{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array(['hate', 'none', 'offensive'], dtype=object),\n",
       " array([ 77, 274, 120], dtype=int64))"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt; t = Okt()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               comments bias_label  \\\n",
       "7891                                         힘내세요,응원합니다       none   \n",
       "7892                                힘내세요,삼가 고인의 명복을 빕니다       none   \n",
       "7893                                      힘내세용 항상 응원합니닷       none   \n",
       "7894  힘내 소연기로 답해요,나도 53살 인데 이런 일 저런 일 다 있더라구 요인격을 믿습...       none   \n",
       "7895                                힘들면 관뒀어야지 그게 현명한 거다       none   \n",
       "\n",
       "      gender_label hate_label                                     news_title  \\\n",
       "7891         False       none                허지웅 허투루 넘길 말 없었다,솔직하게 드러냈던 속 사정   \n",
       "7892         False       none            이혜경 오 캐롤 공연 중 남편 오정욱 부 고 오열 속 발인 종합   \n",
       "7893         False       none                     설경구 송윤아 아들과 즐거운 하루 전 엄마니까요   \n",
       "7894         False       none  SC 현장 연예인 인생 협박 유감 미소 잃은 최민수 보복운전 혐의 2차 공판 종합   \n",
       "7895         False       none                단독 스태프 사망 사고 서른 이지만 결국 오늘 촬영 취소   \n",
       "\n",
       "                                            comment_pos  \\\n",
       "7891  [('힘내세요', 'Verb'), (',', 'Punctuation'), ('응원'...   \n",
       "7892  [('힘내세요', 'Verb'), (',', 'Punctuation'), ('삼가'...   \n",
       "7893  [('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...   \n",
       "7894  [('힘내', 'Verb'), ('소', 'Modifier'), ('연기', 'No...   \n",
       "7895  [('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...   \n",
       "\n",
       "                                              title_pos  \n",
       "7891  [('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...  \n",
       "7892  [('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...  \n",
       "7893  [('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...  \n",
       "7894  [('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...  \n",
       "7895  [('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>bias_label</th>\n      <th>gender_label</th>\n      <th>hate_label</th>\n      <th>news_title</th>\n      <th>comment_pos</th>\n      <th>title_pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7891</th>\n      <td>힘내세요,응원합니다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>허지웅 허투루 넘길 말 없었다,솔직하게 드러냈던 속 사정</td>\n      <td>[('힘내세요', 'Verb'), (',', 'Punctuation'), ('응원'...</td>\n      <td>[('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...</td>\n    </tr>\n    <tr>\n      <th>7892</th>\n      <td>힘내세요,삼가 고인의 명복을 빕니다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>이혜경 오 캐롤 공연 중 남편 오정욱 부 고 오열 속 발인 종합</td>\n      <td>[('힘내세요', 'Verb'), (',', 'Punctuation'), ('삼가'...</td>\n      <td>[('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...</td>\n    </tr>\n    <tr>\n      <th>7893</th>\n      <td>힘내세용 항상 응원합니닷</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>설경구 송윤아 아들과 즐거운 하루 전 엄마니까요</td>\n      <td>[('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...</td>\n      <td>[('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...</td>\n    </tr>\n    <tr>\n      <th>7894</th>\n      <td>힘내 소연기로 답해요,나도 53살 인데 이런 일 저런 일 다 있더라구 요인격을 믿습...</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>SC 현장 연예인 인생 협박 유감 미소 잃은 최민수 보복운전 혐의 2차 공판 종합</td>\n      <td>[('힘내', 'Verb'), ('소', 'Modifier'), ('연기', 'No...</td>\n      <td>[('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...</td>\n    </tr>\n    <tr>\n      <th>7895</th>\n      <td>힘들면 관뒀어야지 그게 현명한 거다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>단독 스태프 사망 사고 서른 이지만 결국 오늘 촬영 취소</td>\n      <td>[('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...</td>\n      <td>[('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "train = pd.read_csv('./datas/train_ver1', index_col=[0])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              comments hate_label\n",
       "466                                  지현우 범죄 저지르지 않았나요?  offensive\n",
       "467                                    여자인생 망칠 일 있나 ㅋㅋ       hate\n",
       "468            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?  offensive\n",
       "469  할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...       hate\n",
       "470  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...       none"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>hate_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>466</th>\n      <td>지현우 범죄 저지르지 않았나요?</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>여자인생 망칠 일 있나 ㅋㅋ</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>470</th>\n      <td>남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...</td>\n      <td>none</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "dev = pd.read_csv('./datas/dev.hate.csv')\n",
    "dev.rename(columns={'label': 'hate_label'}, inplace=True)\n",
    "dev.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_tokenizer(text):\n",
    "    tokens_ko = t.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['...', '....', 'ㅠㅠ', 'ㅜ', 'ㅎㅎ', ',,,', '^^', '!!', '!!!', 'ㅡㅡ', 'ㅋㅋㅋ', 'ㅋ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(tokenizer=t_tokenizer, stop_words=stopwords, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf_vect.fit(train['comments'])\n",
    "tfidf_matrix_train = tfidf_vect.transform(train['comments'])"
   ]
  },
  {
   "source": [
    "## LGBMClassifier compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 9.823092460632324\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "lgbm_clf = LGBMClassifier(n_estimators=400)\n",
    "lgbm_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5498938428874734, 0.542144386766068)"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "\n",
    "tfidf_matrix_dev = tfidf_vect.transform(dev['comments'])\n",
    "preds = lgbm_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "source": [
    "## DecisionTreeClassifier compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 12.927754878997803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_clf = DecisionTreeClassifier(max_depth=2, random_state=13)\n",
    "decision_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.4118895966029724, 0.33302547396349347)"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "preds = decision_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "source": [
    "## LogisticRegression compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 19.302770853042603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', random_state= 13)\n",
    "lr.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5881104033970276, 0.5775181595719191)"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "preds = lr.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "wrong_result = []\n",
    "\n",
    "for n in range(0, len(dev['hate_label'])):\n",
    "    if preds[n] != dev['hate_label'][n]:\n",
    "        wrong_result.append(n)\n",
    "len(wrong_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[232,\n",
       " 442,\n",
       " 212,\n",
       " 157,\n",
       " 279,\n",
       " 263,\n",
       " 16,\n",
       " 226,\n",
       " 446,\n",
       " 308,\n",
       " 31,\n",
       " 358,\n",
       " 239,\n",
       " 303,\n",
       " 166,\n",
       " 248,\n",
       " 255,\n",
       " 346,\n",
       " 470,\n",
       " 73,\n",
       " 36,\n",
       " 387,\n",
       " 380,\n",
       " 345,\n",
       " 325,\n",
       " 119,\n",
       " 127,\n",
       " 271,\n",
       " 30,\n",
       " 263,\n",
       " 303,\n",
       " 43,\n",
       " 403,\n",
       " 35,\n",
       " 15,\n",
       " 37,\n",
       " 442,\n",
       " 301,\n",
       " 217,\n",
       " 303,\n",
       " 223,\n",
       " 426,\n",
       " 269,\n",
       " 403,\n",
       " 314,\n",
       " 359,\n",
       " 293,\n",
       " 353,\n",
       " 88,\n",
       " 172,\n",
       " 224,\n",
       " 293,\n",
       " 219,\n",
       " 173,\n",
       " 312,\n",
       " 438,\n",
       " 258,\n",
       " 403,\n",
       " 301,\n",
       " 114,\n",
       " 119,\n",
       " 103,\n",
       " 255,\n",
       " 235,\n",
       " 55,\n",
       " 113,\n",
       " 37,\n",
       " 351,\n",
       " 71,\n",
       " 330,\n",
       " 426,\n",
       " 73,\n",
       " 281,\n",
       " 403,\n",
       " 263,\n",
       " 431,\n",
       " 425,\n",
       " 164,\n",
       " 470,\n",
       " 303,\n",
       " 435,\n",
       " 399,\n",
       " 341,\n",
       " 250,\n",
       " 66,\n",
       " 179,\n",
       " 36,\n",
       " 30,\n",
       " 115,\n",
       " 61,\n",
       " 19,\n",
       " 393,\n",
       " 49,\n",
       " 401,\n",
       " 434,\n",
       " 122,\n",
       " 367,\n",
       " 66,\n",
       " 370,\n",
       " 46,\n",
       " 111,\n",
       " 92,\n",
       " 181,\n",
       " 232,\n",
       " 184,\n",
       " 433,\n",
       " 220,\n",
       " 351,\n",
       " 147,\n",
       " 434,\n",
       " 2,\n",
       " 19,\n",
       " 374,\n",
       " 273,\n",
       " 209,\n",
       " 258,\n",
       " 394,\n",
       " 41,\n",
       " 387,\n",
       " 50,\n",
       " 55,\n",
       " 69,\n",
       " 98,\n",
       " 436,\n",
       " 16,\n",
       " 101,\n",
       " 16,\n",
       " 223,\n",
       " 83,\n",
       " 259,\n",
       " 15,\n",
       " 225,\n",
       " 302,\n",
       " 367,\n",
       " 92,\n",
       " 209,\n",
       " 425,\n",
       " 401,\n",
       " 156,\n",
       " 29,\n",
       " 141,\n",
       " 37,\n",
       " 219,\n",
       " 241,\n",
       " 324,\n",
       " 442,\n",
       " 70,\n",
       " 10,\n",
       " 401,\n",
       " 431,\n",
       " 29,\n",
       " 308,\n",
       " 330,\n",
       " 163,\n",
       " 394,\n",
       " 217,\n",
       " 366,\n",
       " 359,\n",
       " 220,\n",
       " 44,\n",
       " 458,\n",
       " 322,\n",
       " 297,\n",
       " 293,\n",
       " 273,\n",
       " 393,\n",
       " 331,\n",
       " 50,\n",
       " 199,\n",
       " 119,\n",
       " 367,\n",
       " 337,\n",
       " 138,\n",
       " 367,\n",
       " 163,\n",
       " 415,\n",
       " 388,\n",
       " 414,\n",
       " 220,\n",
       " 193,\n",
       " 11,\n",
       " 223,\n",
       " 226,\n",
       " 2,\n",
       " 122,\n",
       " 50,\n",
       " 380,\n",
       " 149,\n",
       " 173,\n",
       " 141,\n",
       " 312,\n",
       " 379,\n",
       " 101,\n",
       " 111,\n",
       " 212,\n",
       " 323,\n",
       " 66,\n",
       " 295,\n",
       " 235,\n",
       " 15,\n",
       " 171,\n",
       " 172,\n",
       " 84,\n",
       " 351,\n",
       " 119,\n",
       " 84,\n",
       " 415,\n",
       " 73,\n",
       " 179,\n",
       " 89,\n",
       " 133,\n",
       " 159,\n",
       " 466,\n",
       " 374,\n",
       " 367,\n",
       " 273,\n",
       " 401,\n",
       " 246,\n",
       " 425,\n",
       " 312,\n",
       " 98,\n",
       " 323,\n",
       " 84,\n",
       " 11,\n",
       " 442,\n",
       " 124,\n",
       " 216,\n",
       " 292,\n",
       " 332,\n",
       " 23,\n",
       " 95,\n",
       " 119,\n",
       " 101,\n",
       " 259,\n",
       " 69,\n",
       " 357,\n",
       " 198,\n",
       " 431,\n",
       " 19,\n",
       " 345,\n",
       " 269,\n",
       " 179,\n",
       " 46,\n",
       " 365,\n",
       " 252,\n",
       " 308,\n",
       " 63,\n",
       " 111,\n",
       " 224,\n",
       " 396,\n",
       " 341,\n",
       " 157,\n",
       " 448,\n",
       " 138,\n",
       " 157,\n",
       " 22,\n",
       " 393,\n",
       " 78,\n",
       " 230,\n",
       " 224,\n",
       " 73,\n",
       " 341,\n",
       " 74,\n",
       " 173,\n",
       " 151,\n",
       " 365,\n",
       " 192,\n",
       " 414,\n",
       " 138,\n",
       " 414,\n",
       " 2,\n",
       " 157,\n",
       " 70,\n",
       " 19,\n",
       " 166,\n",
       " 422,\n",
       " 220,\n",
       " 324,\n",
       " 301,\n",
       " 212,\n",
       " 147,\n",
       " 172,\n",
       " 159,\n",
       " 184,\n",
       " 295,\n",
       " 71,\n",
       " 239,\n",
       " 23,\n",
       " 47,\n",
       " 409,\n",
       " 19,\n",
       " 301,\n",
       " 28,\n",
       " 210,\n",
       " 96,\n",
       " 193,\n",
       " 209,\n",
       " 259,\n",
       " 229,\n",
       " 71]"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "samples = random.choices(population=wrong_result, k=300)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             0\n",
       "0    offensive\n",
       "1         none\n",
       "2    offensive\n",
       "3    offensive\n",
       "4         none\n",
       "..         ...\n",
       "189       none\n",
       "190       none\n",
       "191       none\n",
       "192       none\n",
       "193       hate\n",
       "\n",
       "[194 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>hate</td>\n    </tr>\n  </tbody>\n</table>\n<p>194 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "df = pd.DataFrame(preds[wrong_result])\r\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              comments hate_label      error\n",
       "2           알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라       hate  offensive\n",
       "3                                     설마 ㅈ 현정 작가 아니지??       hate       none\n",
       "10   이경규가 이런거보면 세련되긴함 저 나이에 차은우 누가 알꼬 아무리 잘생겼다해도. 배...       none  offensive\n",
       "11                                  아c발 어쩌라고 뭔기사가계속나오냐       hate  offensive\n",
       "15                                        둘이 화장실가서 싸우길  offensive       none\n",
       "..                                                 ...        ...        ...\n",
       "463                               강용석도 찌질하네 과거들추기는 추하다  offensive       none\n",
       "466                                  지현우 범죄 저지르지 않았나요?  offensive       none\n",
       "468            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?  offensive       none\n",
       "469  할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...       hate       none\n",
       "470  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...       none       hate\n",
       "\n",
       "[194 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>hate_label</th>\n      <th>error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라</td>\n      <td>hate</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>설마 ㅈ 현정 작가 아니지??</td>\n      <td>hate</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>이경규가 이런거보면 세련되긴함 저 나이에 차은우 누가 알꼬 아무리 잘생겼다해도. 배...</td>\n      <td>none</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>아c발 어쩌라고 뭔기사가계속나오냐</td>\n      <td>hate</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>둘이 화장실가서 싸우길</td>\n      <td>offensive</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>463</th>\n      <td>강용석도 찌질하네 과거들추기는 추하다</td>\n      <td>offensive</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>466</th>\n      <td>지현우 범죄 저지르지 않았나요?</td>\n      <td>offensive</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?</td>\n      <td>offensive</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...</td>\n      <td>hate</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>470</th>\n      <td>남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...</td>\n      <td>none</td>\n      <td>hate</td>\n    </tr>\n  </tbody>\n</table>\n<p>194 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "df1 = dev.iloc[wrong_result]\n",
    "df1['error'] = preds[wrong_result]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./datas/df1_wrong_result', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           hate_label\n",
       "offensive         116\n",
       "hate               61\n",
       "none               14"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hate_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>offensive</th>\n      <td>116</td>\n    </tr>\n    <tr>\n      <th>hate</th>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>none</th>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "df1['hate_label'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           error\n",
       "none         128\n",
       "offensive     47\n",
       "hate          16"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>none</th>\n      <td>128</td>\n    </tr>\n    <tr>\n      <th>offensive</th>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>hate</th>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "df1['error'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array(['hate', 'none', 'offensive'], dtype=object),\n",
       " array([ 77, 274, 120], dtype=int64))"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              comments  label\n",
       "0         ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ      0\n",
       "1                                        둘다 넘 좋다~행복하세요      0\n",
       "2                 근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데      0\n",
       "3                원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요      0\n",
       "4                                   장현승 얘도 참 이젠 짠하다...      1\n",
       "..                                                 ...    ...\n",
       "969                     대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹      0\n",
       "970  성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...      1\n",
       "971  분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...      0\n",
       "972                               입에 손가릭이 10개 있으니 징그럽다      2\n",
       "973                              난 조보아 이뻐서 보는데 백종원 관심무      0\n",
       "\n",
       "[974 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>둘다 넘 좋다~행복하세요</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>장현승 얘도 참 이젠 짠하다...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>969</th>\n      <td>대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>970</th>\n      <td>성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>971</th>\n      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>972</th>\n      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>973</th>\n      <td>난 조보아 이뻐서 보는데 백종원 관심무</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>974 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "test = pd.read_csv('./datas/NaiveBayeji_prediction.csv')\n",
    "test"
   ]
  },
  {
   "source": [
    "## GradientBoostingClassifier compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 20.991591930389404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=13)\n",
    "gb_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5095541401273885, 0.48810533169257236)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "preds = gb_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "source": [
    "## XGBClassifier compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[21:21:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit time: 31.689951181411743\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "xgb_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5265392781316348, 0.506364447945686)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "preds = xgb_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomForestClassifier compare train and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.33970276008492567, 0.16904384574749076)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "r_clf = RandomForestClassifier(max_depth=4, random_state=13)\n",
    "r_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "\n",
    "preds = r_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, class_train, class_test = train_test_split(tfidf_matrix_train, train['hate_label'], test_size=0.2, stratify=train['hate_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = []\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "models.append(('LogisticRegression', LogisticRegression()))\n",
    "models.append(('LGBMClassifier', LGBMClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Acc :  0.9988917036098797\n",
      "Test Acc :  0.5360759493670886\n",
      "Train Acc :  0.9988917036098797\n",
      "Test Acc :  0.46392405063291137\n",
      "Train Acc :  0.5582647245091831\n",
      "Test Acc :  0.510759493670886\n",
      "Train Acc :  0.652786573780874\n",
      "Test Acc :  0.5259493670886076\n",
      "Train Acc :  0.8530715642811906\n",
      "Test Acc :  0.5430379746835443\n",
      "Train Acc :  0.8096896770107663\n",
      "Test Acc :  0.5316455696202531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(msg_train, class_train)\n",
    "    \n",
    "    y_pred_tr = clf.predict(msg_train)\n",
    "    y_pred_test = clf.predict(msg_test)\n",
    "    \n",
    "    print('Train Acc : ', accuracy_score(class_train, y_pred_tr))\n",
    "    print('Test Acc : ', accuracy_score(class_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "names = []\n",
    "f1score = []\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(msg_train, class_train)\n",
    "    \n",
    "    y_pred_tr = clf.predict(msg_train)\n",
    "    y_pred_test = clf.predict(msg_test)\n",
    "    \n",
    "    names.append(name)\n",
    "    test_score.append(accuracy_score(class_test, y_pred_test))\n",
    "    train_score.append(accuracy_score(class_train, y_pred_tr))\n",
    "    f1score.append(f1_score(class_test, y_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   model name  train score  test score  f1 score\n",
       "0      RandomForestClassifier     0.998892    0.532911  0.474092\n",
       "1      DecisionTreeClassifier     0.998892    0.473418  0.441096\n",
       "2          AdaBoostClassifier     0.558265    0.510759  0.444480\n",
       "3  GradientBoostingClassifier     0.652787    0.524684  0.451602\n",
       "4          LogisticRegression     0.853072    0.543038  0.507301\n",
       "5              LGBMClassifier     0.809690    0.531646  0.498601"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model name</th>\n      <th>train score</th>\n      <th>test score</th>\n      <th>f1 score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RandomForestClassifier</td>\n      <td>0.998892</td>\n      <td>0.532911</td>\n      <td>0.474092</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DecisionTreeClassifier</td>\n      <td>0.998892</td>\n      <td>0.473418</td>\n      <td>0.441096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AdaBoostClassifier</td>\n      <td>0.558265</td>\n      <td>0.510759</td>\n      <td>0.444480</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GradientBoostingClassifier</td>\n      <td>0.652787</td>\n      <td>0.524684</td>\n      <td>0.451602</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LogisticRegression</td>\n      <td>0.853072</td>\n      <td>0.543038</td>\n      <td>0.507301</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LGBMClassifier</td>\n      <td>0.809690</td>\n      <td>0.531646</td>\n      <td>0.498601</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "result = pd.DataFrame({'model name':names, \n",
    "                       'train score':train_score, \n",
    "                       'test score':test_score,\n",
    "                       'f1 score': f1score}) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}