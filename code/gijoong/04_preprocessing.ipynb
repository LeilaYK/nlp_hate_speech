{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "def kaggle_format(df):\n",
    "    df['label'][df['label'] == 'none'] = 0\n",
    "    df['label'][df['label'] == 'offensive'] = 1\n",
    "    df['label'][df['label'] == 'hate'] = 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험일지 01 - 05\n",
    "- 실혐 : TF-IDF 백터화 , lgs 모델 적용\n",
    "- 01-03 tfidf max_features 테스트 결과\n",
    "    - f1-macro 점수 \n",
    "        - 140000/ 0.568353(1위) >> dev 0.6171, test 0.52893\n",
    "        - 100000/ 0.567885(3위) >> dev 0.6216, test 0.52899\n",
    "    - max_features list(range(140000, 150001, 1000))\n",
    "        - 전부 똑같음\n",
    "- 01-04 n_gram 값 조정 및 최적의 max_features 찾을 예정\n",
    "    - n_gram 을 늘려서는 답이 없음\n",
    "- 전처리를 늘려가며 테스트\n",
    "    - 띄워쓰기\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최고 성적 f1 score 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# train 데이터 / 7893/ \n",
    "# 'none'/ 'offensive'/ 'hate' : 3486/ 2498/ 1909\n",
    "train = pd.read_csv('total_20210121.csv')\n",
    "train = train[['comments', 'hate']]\n",
    "train.columns = ['comments', 'label']\n",
    "train = kaggle_format(train)\n",
    "train = train.astype({'label': 'str'})\n",
    "\n",
    "# dev 데이터 / 471/ \n",
    "# 'none'/ 'offensive'/ 'hate' : 160/ 189/ 122\n",
    "dev = pd.read_csv('./korean-hate-speech-master/labeled/dev.tsv', sep='\\t')\n",
    "dev = dev[['comments', 'hate']]\n",
    "dev.columns = ['comments', 'label']\n",
    "dev = kaggle_format(dev)\n",
    "dev = dev.astype({'label': 'str'})\n",
    "\n",
    "test = pd.read_csv('./korean-hate-speech-master/test.no_label.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.comments, train.label\n",
    "X_test, y_test = dev.comments, dev.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=0.0, analyzer='char', ngram_range=(1,3), sublinear_tf=True,\n",
    "               max_features=100000)\n",
    "X_tf = tfidf.fit_transform(X, y)\n",
    "X_dev = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=1, \n",
    "                              class_weight='balanced', \n",
    "                              max_iter=6000,\n",
    "                             random_state=13).fit(X_tf, y)\n",
    "pred = lr_model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6171504866913602"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "baseline = f1_score(y_test, pred, average='macro')\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리\n",
    "- soynlp 패키지사용\n",
    "    - 반복제거 기능 사용시 ㅋㅋㅋ과 단어가 붙어있는 경우 그단어도 반복으로 포함 제거\n",
    "        - ex) ㅋㅋ듣보잡 -> ㅋㅋ보잡 / 욕한다는게ㅋㅋㅋㅋㅋㅋ역시 -> 욕한다는ㅋㅋ시\n",
    "- Okt --> 반복 제거를 위해 ㅋㅋㅋ과 같은것을 띄워야함\n",
    "    - 그랬을때 부작용은 맞춤법이 지켜지지 않은 데이터다 보니 분류에 오류가 있음\n",
    "        - ex) 듣보잡 기사내보 장난하냐구 -> 듣보잡 기 사 내 보 장난 하냐구\n",
    "            - 동영상보니깐가관 -> 동 영 상보 니깐 가관 \n",
    "- 다시, soynlp를 사용해서 형태 분석 -> 기존 분석기는 신조어에 취약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 제거 확인\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "test = pd.DataFrame()\n",
    "ls = []\n",
    "for c in X:\n",
    "    ment = repeat_normalize(c, num_repeats=1)\n",
    "    ls.append(ment)\n",
    "\n",
    "test['comments'] = X\n",
    "test['soynlp'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "원본 :  ㅋㅋㅋㅋㅋㅋㅋ애초에 여자들이 왜욕하는데? 성상품화때문아님? 저 기사 댓글에 한남새 기들 성희롱 오지는데 그딴 스 레기짓만 안해도 성상품화한다고 욕먹지 않음 한남들 지들 때문에 욕먹는건 모르고 좋다고 성희롱 오지네 \n",
      "반복제거 :  ㅋ애초에 여자들이 왜욕하는데? 성상품화때문아님? 저 기사 댓글에 한남새 기들 성희롱 오지는데 그딴 스 레기짓만 안해도 성상품화한다고 욕먹지 않음 한남들 지들 때문에 욕먹는건 모르고 좋다고 성희롱 오지네 \n",
      "\n",
      "\n",
      "1337\n",
      "원본 :  너네 댓글 조심해라 그러다 고소당한다 ~ 아무리 그래도 니네 한테 잘못한건 없으니 가려서해 할짓없는것들 남욕은 오지게 조아하지 특히 맘충들 ㅠㅠㅠㅠㅠㅠㅠ 쯧쯧...... \n",
      "반복제거 :  너네 댓글 조심해라 그러다 고소당한다 ~ 아무리 그래도 니네 한테 잘못한건 없으니 가려서해 할짓없는것들 남욕은 오지게 조아하지 특히 맘충들 ㅠ 쯧쯧...... \n",
      "\n",
      "\n",
      "1367\n",
      "원본 :  아니 근데.튜닝한사람은 프러포즈받지도.결혼도못함?ㅋㅋㅋ지들은 돈없어서 못하는것들이ㅋㅋㅋㅋ아이고배아퍼죽지ㅋ \n",
      "반복제거 :  아니 근데.튜닝한사람은 프러포즈받지도.결혼도못함?ㅋㅋㅋ지들은 돈없어서 못하는것들이ㅋ아이고배아퍼죽지ㅋ \n",
      "\n",
      "\n",
      "1374\n",
      "원본 :  잘나가고 돈많은데 차별하면 어떠냐ㅋㅋㅋㅋㅋ똥양인은 차별당할 만한 외모기도하고ㅎ백인들 찬양하자그냥 \n",
      "반복제거 :  잘나가고 돈많은데 차별하면 어떠냐ㅋ똥양인은 차별당할 만한 외모기도하고ㅎ백인들 찬양하자그냥 \n",
      "\n",
      "\n",
      "1381\n",
      "원본 :  아무리 방탄이 대단하다고 하지만 내년엔 워너원도 없고 과연 시상식장이 꽉 채워질까?ㅋㅋㅋㅋ \n",
      "반복제거 :  아무리 방탄이 대단하다고 하지만 내년엔 워너원도 없고 과연 시상식장이 꽉 채워질까?ㅋ \n",
      "\n",
      "\n",
      "1387\n",
      "원본 :  평소엔 현대예술 관심도 없던 아줌마들이 방탄 무대 하나보고 마치 예술,문학에 통달한것처럼 말하는것보면 그냥 같잖고 웃김ㅋㅋㅋㅋㅋ \n",
      "반복제거 :  평소엔 현대예술 관심도 없던 아줌마들이 방탄 무대 하나보고 마치 예술,문학에 통달한것처럼 말하는것보면 그냥 같잖고 웃김ㅋ \n",
      "\n",
      "\n",
      "1388\n",
      "원본 :  미국병 오지게들었네ㅋㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  미국병 오지게들었네ㅋ \n",
      "\n",
      "\n",
      "1394\n",
      "원본 :  얘네 팬덤 만큼 완장질에 법적대응 잘하는 가수도 없지 나이때가 할매 꼰머들이라 생각 자체가 굳은듯 ㅋ 유연해질 필요가있어요 인기가 항상 멈춰있는것은 아닐테니까 ㅋㅋㅋㅋ \n",
      "반복제거 :  얘네 팬덤 만큼 완장질에 법적대응 잘하는 가수도 없지 나이때가 할매 꼰머들이라 생각 자체가 굳은듯 ㅋ 유연해질 필요가있어요 인기가 항상 멈춰있는것은 아닐테니까 ㅋ \n",
      "\n",
      "\n",
      "1397\n",
      "원본 :  ㅋㅋㅋㅋ게이인줄 ㅋㅋㅋ옷이랑 화장좀봨ㅋㅋㅋㅋ \n",
      "반복제거 :  ㅋ게이인줄 ㅋㅋㅋ옷이랑 화장좀봨ㅋ \n",
      "\n",
      "\n",
      "1401\n",
      "원본 :  엑소엘에게 맨날 쳐맞던 빵셔틀 아미들이였는데 많이컸네 ㅋㅋㅋㅋ짜져라 \n",
      "반복제거 :  엑소엘에게 맨날 쳐맞던 빵셔틀 아미들이였는데 많이컸네 ㅋ짜져라 \n",
      "\n",
      "\n",
      "1454\n",
      "원본 :  지는 교육받으면 얼마나 받았다고 ㅋㅋㅋㅋ 어디대학 나옴? \n",
      "반복제거 :  지는 교육받으면 얼마나 받았다고 ㅋ 어디대학 나옴? \n",
      "\n",
      "\n",
      "1504\n",
      "원본 :  ㅋㅋㅋㅋㅋㅋ 욕하는분들 평생 욕 안해보고 사신분?별게 다 불편해~~~~ \n",
      "반복제거 :  ㅋ 욕하는분들 평생 욕 안해보고 사신분?별게 다 불편해~~~~ \n",
      "\n",
      "\n",
      "1527\n",
      "원본 :  지금으로따지면 뷔+정국 느낌? 당시에 여자들이라면 믹키유천 좋아하긴함ㅋㅋㅋㅋㅋ \n",
      "반복제거 :  지금으로따지면 뷔+정국 느낌? 당시에 여자들이라면 믹키유천 좋아하긴함ㅋ \n",
      "\n",
      "\n",
      "1546\n",
      "원본 :  블랙리스트에 올린 자한당보단 낫지않음?축하하려고 초청한건데 너무 예민하게 반응하네ㅋㅋㅋㅋㅋㅋㅋ자한당은 세금으로 박물관 세울거란다난 좌파 우파 둘다 싫은데 우파가 더 토나옴ㅋㅋ \n",
      "반복제거 :  블랙리스트에 올린 자한당보단 낫지않음?축하하려고 초청한건데 너무 예민하게 반응하네ㅋ자한당은 세금으로 박물관 세울거란다난 좌파 우파 둘다 싫은데 우파가 더 토나옴ㅋㅋ \n",
      "\n",
      "\n",
      "1600\n",
      "원본 :  이게 정준영 잘못임?당연히 걸린이상 연예인 인생도 끝난셈인데 어떤 ㅂ.ㅅ이 저걸 공장초기화를 안하겠어?강아지같은 경찰분들이 제대로 수사를 안한거지 ㅋㅋㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  이게 정준영 잘못임?당연히 걸린이상 연예인 인생도 끝난셈인데 어떤 ㅂ.ㅅ이 저걸 공장초기화를 안하겠어?강아지같은 경찰분들이 제대로 수사를 안한거지 ㅋ \n",
      "\n",
      "\n",
      "1622\n",
      "원본 :  참지않긬ㅋㅋㅋㅋㅋㅋㅋ 계집애 종특 그대로 표현했네 ㅋㅋ 남태현 장하다 남자가 그럴수도잇지 ㅋㅋㅋ \n",
      "반복제거 :  참지않긬ㅋ 계집애 종특 그대로 표현했네 ㅋㅋ 남태현 장하다 남자가 그럴수도잇지 ㅋㅋㅋ \n",
      "\n",
      "\n",
      "1623\n",
      "원본 :  ㅋㅋㅋㅋㅋ 개그맨 하셔도 되겠습니다 올해 들은 개그중 최고로 웃겼습니다 \n",
      "반복제거 :  ㅋ 개그맨 하셔도 되겠습니다 올해 들은 개그중 최고로 웃겼습니다 \n",
      "\n",
      "\n",
      "1630\n",
      "원본 :  미쳐버린 남태현빠순이들 댓글 모음창 닫을 줄도 몰라서 다 열어둔채로 일반인 코스프레 웩 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 줌내 지리고요 열폭 오지고요 ㅋㅋ탈덕은 지능순 모르면 외워 \n",
      "반복제거 :  미쳐버린 남태현빠순이들 댓글 모음창 닫을 줄도 몰라서 다 열어둔채로 일반인 코스프레 웩 ㅋ 줌내 지리고요 열폭 오지고요 ㅋㅋ탈덕은 지능순 모르면 외워 \n",
      "\n",
      "\n",
      "1643\n",
      "원본 :  기사가 스포네ㅋㅋㅋㅋ \n",
      "반복제거 :  기사가 스포네ㅋ \n",
      "\n",
      "\n",
      "1677\n",
      "원본 :  저게 어딜봐서 비키니.. 수영복이구만ㅋㅋ 김준현 유민상 문세윤이 남성용 팬티 수영복 입었음 이런 기사 1도 안떴겠지?ㅎㅎㅎㅎ 뚱뚱한 남자도 결혼식 잘만 하는데 여자만 살빼야되는 후진국ㅉㅉ \n",
      "반복제거 :  저게 어딜봐서 비키니.. 수영복이구만ㅋㅋ 김준현 유민상 문세윤이 남성용 팬티 수영복 입었음 이런 기사 1도 안떴겠지?ㅎ 뚱뚱한 남자도 결혼식 잘만 하는데 여자만 살빼야되는 후진국ㅉㅉ \n",
      "\n",
      "\n",
      "1681\n",
      "원본 :  부러우면 지는거지~~ 참하고 이쁘구만~ㅋ장예원보다 이쁘구만~~ ㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  부러우면 지는거지~~ 참하고 이쁘구만~ㅋ장예원보다 이쁘구만~~ ㅋ \n",
      "\n",
      "\n",
      "1691\n",
      "원본 :  김포맘들 우루루몰려가서깽판친거랑 같네 ㄷㄷㄷㄷㄷㄷㄷ \n",
      "반복제거 :  김포맘들 우루루몰려가서깽판친거랑 같네 ㄷ \n",
      "\n",
      "\n",
      "1744\n",
      "원본 :  할배가 지 분수를 알아야지 어린여자랑 기어코 결혼을 하네? ㅋㅋㅋㅋㅋㅋㅋㅋ 여성분 고생길 훤하노 \n",
      "반복제거 :  할배가 지 분수를 알아야지 어린여자랑 기어코 결혼을 하네? ㅋ 여성분 고생길 훤하노 \n",
      "\n",
      "\n",
      "1745\n",
      "원본 :  어휴 좀더 어린분 만나서 결혼하시지 ㅋㅋㅋㅋㅋㅋㅋㅋ어휴 2세 안볼거에요 건모형 여자나이 40이면 끝난거에요 병원가서 검사부터 받아보세요 임신가능한가 \n",
      "반복제거 :  어휴 좀더 어린분 만나서 결혼하시지 ㅋ어휴 2세 안볼거에요 건모형 여자나이 40이면 끝난거에요 병원가서 검사부터 받아보세요 임신가능한가 \n",
      "\n",
      "\n",
      "1798\n",
      "원본 :  이쁘네 ㅋㅋㅋ 오크먜갈년들 또 심통난거냐 ? 왜 ㅂㄷㅂㄷ 욕하고난리냐 ㅋㅋㅋ 하긴 니네면상은 견적이안나오니 ㅋㅋㅋㅋ \n",
      "반복제거 :  이쁘네 ㅋㅋㅋ 오크먜갈년들 또 심통난거냐 ? 왜 ㅂㄷㅂㄷ 욕하고난리냐 ㅋㅋㅋ 하긴 니네면상은 견적이안나오니 ㅋ \n",
      "\n",
      "\n",
      "1830\n",
      "원본 :  진짜 연기가 창피해서 그런걸까?ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  진짜 연기가 창피해서 그런걸까?ㅋ \n",
      "\n",
      "\n",
      "1861\n",
      "원본 :  와 김경진도 결혼하는데ㅎㅎㅎㅎ \n",
      "반복제거 :  와 김경진도 결혼하는데ㅎ \n",
      "\n",
      "\n",
      "1874\n",
      "원본 :  맞는 말 하긴 했는데ㅋㅋㅋㅋ 일본에서 말하는 바람에 디지게 쳐맞는 중 \n",
      "반복제거 :  맞는 말 하긴 했는데ㅋ 일본에서 말하는 바람에 디지게 쳐맞는 중 \n",
      "\n",
      "\n",
      "1891\n",
      "원본 :  대한민국 금메달리스트가 꼭 이 시국에 쪽ㅂㄹ랑 결혼까지 해야 속이 후련햇냐ㅕㅑㅑㅑㅑㅑ \n",
      "반복제거 :  대한민국 금메달리스트가 꼭 이 시국에 쪽ㅂㄹ랑 결혼까지 해야 속이 후련햇냐ㅕㅑ \n",
      "\n",
      "\n",
      "1900\n",
      "원본 :  자한당이 싫어 하는 연예인들은 계속 조질꺼임 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 김제동 김건모 유재석 다음은 누구냐 \n",
      "반복제거 :  자한당이 싫어 하는 연예인들은 계속 조질꺼임 ㅋ 김제동 김건모 유재석 다음은 누구냐 \n",
      "\n",
      "\n",
      "1952\n",
      "원본 :  이렇게 기사 떠도 음모론 믿는 새끼들은 성노예 같은 자극적인 얘기만 쳐믿ㅈㅣㅋㅋㅋㅋ 진짜 덜떨어진 새끼들 같애 \n",
      "반복제거 :  이렇게 기사 떠도 음모론 믿는 새끼들은 성노예 같은 자극적인 얘기만 쳐믿ㅈㅣㅋ 진짜 덜떨어진 새끼들 같애 \n",
      "\n",
      "\n",
      "1966\n",
      "원본 :  설리가 이뻐서 질투하는 한녀들 겁나 많네 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 이쁜게 부러우면 부럽다고해 \n",
      "반복제거 :  설리가 이뻐서 질투하는 한녀들 겁나 많네 ㅋ 이쁜게 부러우면 부럽다고해 \n",
      "\n",
      "\n",
      "1999\n",
      "원본 :  역시 경규옹ㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  역시 경규옹ㅋ \n",
      "\n",
      "\n",
      "2011\n",
      "원본 :  반대상황이었음 남자 ㅈㄴ까겠지 ㅂㅅ페미 쿵쾅이들 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ 무슨 이모랑 결혼해서 사냐 남자 부모 개불쌍하다 \n",
      "반복제거 :  반대상황이었음 남자 ㅈㄴ까겠지 ㅂㅅ페미 쿵쾅이들 ㅋ 무슨 이모랑 결혼해서 사냐 남자 부모 개불쌍하다 \n",
      "\n",
      "\n",
      "2032\n",
      "원본 :  인버마아 ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ 보고싶었어 ㅠㅠㅠㅠㅠ \n",
      "반복제거 :  인버마아 ㅠ 보고싶었어 ㅠ \n",
      "\n",
      "\n",
      "2043\n",
      "원본 :  둘이 사귀는구나 ㅠㅠㅠㅠㅠㅠㅠ 잘어울리는데 너무부럽다 \n",
      "반복제거 :  둘이 사귀는구나 ㅠ 잘어울리는데 너무부럽다 \n",
      "\n",
      "\n",
      "2066\n",
      "원본 :  2,30대 골빈여자들은 이 기사에 다 모이는건가ㅋㅋㅋㅋ 이래서 여자는 투표권 주면 안된다. 엠넷사전투표나 하고 살아야지 계집들은 \n",
      "반복제거 :  2,30대 골빈여자들은 이 기사에 다 모이는건가ㅋ 이래서 여자는 투표권 주면 안된다. 엠넷사전투표나 하고 살아야지 계집들은 \n",
      "\n",
      "\n",
      "2072\n",
      "원본 :  박명수는 그렇다 쳐도 김제동은 뭔데 저기에 꼽사리껴있음?ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  박명수는 그렇다 쳐도 김제동은 뭔데 저기에 꼽사리껴있음?ㅋ \n",
      "\n",
      "\n",
      "2089\n",
      "원본 :  오늘 짱 재밋었다 ㅋㅋㅋㅋ 홍진영 애교 굿굿 \n",
      "반복제거 :  오늘 짱 재밋었다 ㅋ 홍진영 애교 굿굿 \n",
      "\n",
      "\n",
      "2133\n",
      "원본 :  여러분!!! 오늘 고현정이 어떤남자 욕조에서 샤워기로 물뿌리고 때리는거 개웃기지 않았나요? 저 엄청 뿜었어요 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  여러분!!! 오늘 고현정이 어떤남자 욕조에서 샤워기로 물뿌리고 때리는거 개웃기지 않았나요? 저 엄청 뿜었어요 ㅋ \n",
      "\n",
      "\n",
      "2153\n",
      "원본 :  38세48세로 잘못적은거아닌가ㅋㅋㅋㅋ할정도로 동안이네요~~~ \n",
      "반복제거 :  38세48세로 잘못적은거아닌가ㅋ할정도로 동안이네요~~~ \n",
      "\n",
      "\n",
      "2157\n",
      "원본 :  아줌마들 또 와서 ㅂㄷㅂㄷ거리네 ㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  아줌마들 또 와서 ㅂㄷㅂㄷ거리네 ㅋ \n",
      "\n",
      "\n",
      "2180\n",
      "원본 :  ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ열폭들 한다고 난리났다 진짴ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  ㅋ열폭들 한다고 난리났다 진짴ㅋ \n",
      "\n",
      "\n",
      "2199\n",
      "원본 :  ㅋㅋㅋ 츄 ㅋㅋㅋ 짠내투어에서 봤다 ㅋㅋㅋㅋㅋ 정말 해맑드라 ㅋㅋㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  ㅋㅋㅋ 츄 ㅋㅋㅋ 짠내투어에서 봤다 ㅋ 정말 해맑드라 ㅋ \n",
      "\n",
      "\n",
      "2202\n",
      "원본 :  츄가 뭐냐ㅋㅋㅋㅋ 피카츄냐 \n",
      "반복제거 :  츄가 뭐냐ㅋ 피카츄냐 \n",
      "\n",
      "\n",
      "2219\n",
      "원본 :  근데 인터넷에서만 욕하지 ㅡ 지금 싸이콘서트 매진임 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ나도 가고싶음 ㅋㅋㅋㅋㅋㅋ \n",
      "반복제거 :  근데 인터넷에서만 욕하지 ㅡ 지금 싸이콘서트 매진임 ㅋ나도 가고싶음 ㅋ \n",
      "\n",
      "\n",
      "2245\n",
      "원본 :  송혜교는 예쁜데 댓글이 너무 인위적이라 보니까 30-40대 비율ㅋㅋㅋㅋㅋ역시 나이많은 여자는 나이많은 여자보고 예쁘다 하는구나 \n",
      "반복제거 :  송혜교는 예쁜데 댓글이 너무 인위적이라 보니까 30-40대 비율ㅋ역시 나이많은 여자는 나이많은 여자보고 예쁘다 하는구나 \n",
      "\n",
      "\n",
      "2265\n",
      "원본 :  ㅋㅋㅋㅋㅋㅋㅋㅋ ㅋㅋㅋㅋㅋㅋㅋ 사기꾼 자식이었어 ㅋㅋㅋㅋㅋ \n",
      "반복제거 :  ㅋ ㅋ 사기꾼 자식이었어 ㅋ \n",
      "\n",
      "\n",
      "2285\n",
      "원본 :  고영욱은 언제나옴? 촤하하하하하하 \n",
      "반복제거 :  고영욱은 언제나옴? 촤하 \n",
      "\n",
      "\n",
      "2324\n",
      "원본 :  백종원 요즘 너무 띄워주네...백종원 이기세면 정치판에 뛰어들어서 대통령 할기세네 ㅋㅋㅋㅋ \n",
      "반복제거 :  백종원 요즘 너무 띄워주네...백종원 이기세면 정치판에 뛰어들어서 대통령 할기세네 ㅋ \n",
      "\n",
      "\n",
      "2331\n",
      "원본 :  저게...?합의된 연기가아니였다구?신고?저여성분도참별난듯저정도로ᆢ연기하다가 진짜싫음ㅋㅋㅋㅋ \n",
      "반복제거 :  저게...?합의된 연기가아니였다구?신고?저여성분도참별난듯저정도로ᆢ연기하다가 진짜싫음ㅋ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 반복제거 기능 동작한 문장 확인\n",
    "dif_idx = test[test.comments != test.soynlp].index\n",
    "\n",
    "for idx in dif_idx[49:100]:\n",
    "    print(idx)\n",
    "    print('원본 : ', test['comments'][idx],'\\n반복제거 : ', test['soynlp'][idx], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okt 사용 한것 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss\n",
    "from konlpy.tag import Okt\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "okt = Okt()\n",
    "ls = []\n",
    "for c in X:\n",
    "    ment = ' '.join(okt.morphs(c)) \n",
    "    ls.append(ment)\n",
    "test['okt'] = ls\n",
    "# print('원본 : ', sample)\n",
    "# print(okt.morphs(sample))\n",
    "# print(kss.split_sentences(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7659\n",
      "50\n",
      "원본 :  어우 난 남잔데..저리 마른여자는 좀 징그럽더라 살좀있는여자가 건강미있어보이고 좋음 \n",
      "okt :  어우 난 남잔 데 .. 저리 마른 여자 는 좀 징그럽더라 살 좀있는 여자 가 건강미 있어 보이 고 좋음 \n",
      "\n",
      "\n",
      "51\n",
      "원본 :  태국 가서 머했을까...궁금궁금 \n",
      "okt :  태국 가서 머 했을까 ... 궁금궁금 \n",
      "\n",
      "\n",
      "52\n",
      "원본 :  현아가 눈이 상당히 낮아 ㅋ \n",
      "okt :  현아 가 눈 이 상당히 낮아 ㅋ \n",
      "\n",
      "\n",
      "53\n",
      "원본 :  솔직히 내가 연예인 메이크업하고 옷 좀 걸치면 이던이 정도는 가뿐할듯 \n",
      "okt :  솔직히 내 가 연예인 메이크업 하고 옷 좀 걸치면 이 던 이 정도 는 가뿐할듯 \n",
      "\n",
      "\n",
      "54\n",
      "원본 :  회사짤려 욕쳐먹어 쫌있음 개인스케줄 만남소원해져서 이별 할거뻔하고 저것들이 가수냐 댄서지 댄서들 끝은 99프로 새드앤딩 그리고 철이없어도 너무없다 \n",
      "okt :  회사 짤려 욕 쳐 먹어 쫌있음 개인 스케줄 만남소 원해져서 이별 할거 뻔하고 저 것 들 이 가수 냐 댄서 지 댄서 들 끝 은 99 프로 새드앤딩 그리고 철 이 없어도 너무 없다 \n",
      "\n",
      "\n",
      "55\n",
      "원본 :  얘네 근데 너무 오바들 떨긴하네 ㅋㅋㅋ 이해가 간다 소속사가 슬슬 \n",
      "okt :  얘 네 근데 너무 오 바 들 떨긴하네 ㅋㅋㅋ 이해 가 간다 소속사 가 슬슬 \n",
      "\n",
      "\n",
      "56\n",
      "원본 :  이던이 인기를 끌면 무조건 현아는 버려진다. \n",
      "okt :  이 던 이 인기 를 끌 면 무조건 현아 는 버려진다 . \n",
      "\n",
      "\n",
      "57\n",
      "원본 :  이런 걸 왜 찍는걸까? 성관계 동영상 찍는 거랑 같은 거 아닌가? \n",
      "okt :  이런 걸 왜 찍는걸 까 ? 성관계 동영상 찍는 거 랑 같은 거 아닌가 ? \n",
      "\n",
      "\n",
      "58\n",
      "원본 :  멋있기만 하구만.이러다 헤어지면 헤어지는거지뭐.연예할때 맘껏 즐기는거 보기 좋은데.내숭보단 훨씬 낫다.화이팅!! \n",
      "okt :  멋있기만 하구만 . 이러다 헤어지면 헤어지는거지 뭐 . 연예 할 때 맘껏 즐기는거 보기 좋은데 . 내 숭보 단 훨씬 낫다 . 화이팅 !! \n",
      "\n",
      "\n",
      "60\n",
      "원본 :  ㅋㅋㅋ 생각이라는 걸 하고 산다면...ㅋㅋㅋㅋ \n",
      "okt :  ㅋㅋㅋ 생각 이라는 걸 하고 산다 면 ... ㅋㅋㅋㅋ \n",
      "\n",
      "\n",
      "61\n",
      "원본 :  적당히좀 해라. \n",
      "okt :  적당히 좀 해 라 . \n",
      "\n",
      "\n",
      "62\n",
      "원본 :  나이조어린것들이 병이 왜캐많어 빠져갖고 \n",
      "okt :  나이 조 어린것 들이 병 이 왜캐 많어 빠져 갖고 \n",
      "\n",
      "\n",
      "63\n",
      "원본 :  안 응원 해요 당신 보다 힘든 사람 세고 셌음 \n",
      "okt :  안 응원 해 요 당신 보다 힘든 사람 세고 셌음 \n",
      "\n",
      "\n",
      "64\n",
      "원본 :  프로다운대처는 무슨..그러고 돌아다니면 애들이 따라한다 행실을 똑바로해라.. \n",
      "okt :  프로 다운 대처 는 무슨 .. 그러고 돌아다니면 애 들 이 따라 한다 행실 을 똑바로 해라 .. \n",
      "\n",
      "\n",
      "65\n",
      "원본 :  화나요는 다 여자가누른듯, , ,,인정하면 up, , , \n",
      "okt :  화나 요 는 다 여자 가 누른듯 , , ,, 인정 하면 up , , , \n",
      "\n",
      "\n",
      "66\n",
      "원본 :  ㅇㅅㅇ 여자들은 싫어합니다 \n",
      "okt :  ㅇㅅㅇ 여자 들 은 싫어합니다 \n",
      "\n",
      "\n",
      "67\n",
      "원본 :  선미에게 쳐발리는 현아 \n",
      "okt :  선미 에게 쳐 발리는 현아 \n",
      "\n",
      "\n",
      "68\n",
      "원본 :  그걸 즐기는 거면 할 말은 없다만~ ㅋㅋㅋㅋ 같은 저러는 거 이해가 안 되긴 함 ㅋㅋㅋㅋㅋㅋ \n",
      "okt :  그걸 즐기는 거 면 할 말 은 없다만 ~ ㅋㅋㅋㅋ 같은 저러는 거 이해 가 안 되긴 함 ㅋㅋㅋㅋㅋㅋ \n",
      "\n",
      "\n",
      "70\n",
      "원본 :  단이 불쌍해서 마지막 안봤어 퉤다 \n",
      "okt :  단 이 불쌍해서 마지막 안 봤어 퉤 다 \n",
      "\n",
      "\n",
      "71\n",
      "원본 :  한때나마 내가 예진이를 좋아했다는게 너무 창피하다 ㅠ 아줌마 예진이... 이건 아니거던... 아... 나 엄청 챙피 꽥하고파 ㅠ \n",
      "okt :  한 때 나마 내 가 예진 이를 좋아했다는게 너무 창피하다 ㅠ 아줌마 예진 이 ... 이건 아니거던 ... 아 ... 나 엄청 챙피 꽥 하고파 ㅠ \n",
      "\n",
      "\n",
      "72\n",
      "원본 :  여주 남주 밉상이야 이기적인 종자들 \n",
      "okt :  여주 남주 밉 상이 야 이 기적 인 종자 들 \n",
      "\n",
      "\n",
      "73\n",
      "원본 :  정우성도 드라마 하나 찍어라. 정우성표 로맨스 보고 싶다. 잘생긴 아저씨의 대표주자. 비트 때는 정말 인간이 아니었는데... 뭔가 잘생겼는데 우수에 찬 느낌도 있고....그냥 잘생기지 않았음 정우성은. \n",
      "okt :  정우성 도 드라마 하나 찍어라 . 정우 성표 로맨스 보고 싶다 . 잘생긴 아저씨 의 대표 주자 . 비트 때 는 정말 인간 이 아니었는데 ... 뭔가 잘생겼는데 우수 에 찬 느낌 도 있고 .... 그냥 잘생기지 않았음 정우성 은 . \n",
      "\n",
      "\n",
      "74\n",
      "원본 :  용두사미. 실망했어요. \n",
      "okt :  용두사미 . 실망했어요 . \n",
      "\n",
      "\n",
      "75\n",
      "원본 :  아휴 이런 유치한 스토리를 재밌다고 빨아주는 킴치련 한녀들때문에 대한민국 드라마 발전이 없는거야 \n",
      "okt :  아 휴 이런 유치한 스토리 를 재밌다고 빨아주는 킴치련 한 녀 들 때문 에 대한민국 드라마 발전 이 없는거야 \n",
      "\n",
      "\n",
      "76\n",
      "원본 :  개인적으로 눈물 씬은 윤세리보다 서단이 훨씬 슬펐음 \n",
      "okt :  개인 적 으로 눈물 씬 은 윤세리 보다 서단 이 훨씬 슬펐음 \n",
      "\n",
      "\n",
      "77\n",
      "원본 :  쉰내나는 40대 아줌마들이 빠는 이드라마 이제 랭킹 뉴스에서 이제 안보게되서 너무기쁨 40대 아줌마 아저씨 로맨스라 1도 몰입안됨 ㅋㅋㅋ \n",
      "okt :  쉰내나는 40 대 아줌마 들 이 빠는 이 드라마 이제 랭킹 뉴스 에서 이제 안보 게 되서 너무 기쁨 40 대 아줌마 아저씨 로맨스 라 1 도 몰입 안됨 ㅋㅋㅋ \n",
      "\n",
      "\n",
      "78\n",
      "원본 :  담배피고 맨날전자레인지에돌려서먹고끼니도 제대로안먹으니깐병생긴거지이참에 금연도하고 몸좀챙겨라 \n",
      "okt :  담배 피고 맨날 전자레인지 에 돌려서 먹고 끼니 도 제 대 로안 먹으니깐 병 생긴거지 이참 에 금연 도하 고 몸좀 챙겨라 \n",
      "\n",
      "\n",
      "80\n",
      "원본 :  이건 혈액암이기때문에 맞는 항암제를 찾아도 재발률이 높고 악성이라 생존률이 희박함 \n",
      "okt :  이건 혈액암 이 기 때문 에 맞는 항암제 를 찾아도 재발 률 이 높고 악성 이라 생존 률 이 희박함 \n",
      "\n",
      "\n",
      "81\n",
      "원본 :  지웅아 치료 잘받고 꼭 살아라 ! \n",
      "okt :  지웅 아 치료 잘 받고 꼭 살아라 ! \n",
      "\n",
      "\n",
      "82\n",
      "원본 :  사내자슥이 비실비실 할때부터 알아봤다!!! \n",
      "okt :  사내 자 슥 이 비실 비실 할 때 부터 알아봤다 !!! \n",
      "\n",
      "\n",
      "83\n",
      "원본 :  당신을 믿습니다꼭 전보다 더 건강한 모습으로 만나요멋진 허지웅 화이팅! \n",
      "okt :  당신 을 믿습니다 꼭 전보 다 더 건강한 모습 으로 만나요 멋진 허지웅 화이팅 ! \n",
      "\n",
      "\n",
      "84\n",
      "원본 :  비호감인데,,,,나대니까 병에걸리지아무튼 관리잘하시길 \n",
      "okt :  비호감 인데 ,,,, 나대니까 병 에 걸리지 아무튼 관리 잘 하시길 \n",
      "\n",
      "\n",
      "85\n",
      "원본 :  좋은 말만 해두 못 사는 세상 \n",
      "okt :  좋은 말 만 해 두 못 사는 세상 \n",
      "\n",
      "\n",
      "86\n",
      "원본 :  힘내세요~ 응원합니다!! \n",
      "okt :  힘내세요 ~ 응원 합니다 !! \n",
      "\n",
      "\n",
      "87\n",
      "원본 :  ㅋㅋㅋ 개꼬시다 \n",
      "okt :  ㅋㅋㅋ 개꼬시 다 \n",
      "\n",
      "\n",
      "89\n",
      "원본 :  그래 그동안 아니꼽게 봤지만 그래도 아프다니까 치료에 전념해서 꼭 완쾌하길 \n",
      "okt :  그래 그동안 아니꼽게 봤지만 그래도 아프다니까 치료 에 전념 해서 꼭 완쾌 하길 \n",
      "\n",
      "\n",
      "90\n",
      "원본 :  꺼어어어어억~~ 아.. 점심 소화 잘 안되네 \n",
      "okt :  꺼 어어어어 억 ~~ 아 .. 점심 소화 잘 안되네 \n",
      "\n",
      "\n",
      "91\n",
      "원본 :  안타깝지만 평소 생활습관이 독이된거같네요완치하시길바랍니다 \n",
      "okt :  안타깝지만 평소 생활 습관 이 독 이 된거 같네요 완치 하시길 바랍니다 \n",
      "\n",
      "\n",
      "92\n",
      "원본 :  병은 안타깝지만 티비에 안나온다니 개이득이네요 \n",
      "okt :  병 은 안타깝지만 티비 에 안 나온다니 개이득 이네 요 \n",
      "\n",
      "\n",
      "93\n",
      "원본 :  우리나라 의학기술의 발달은 실로 놀랍다 \n",
      "okt :  우리나라 의학 기술 의 발달 은 실로 놀랍다 \n",
      "\n",
      "\n",
      "94\n",
      "원본 :  요즘같이 개, 고양이 반려동물 문화가 잘돼있는 시기에...ㅠㅠ 그렇게 한남들이 좋던가요? 진짜 실망을 넘어 분노합니다. \n",
      "okt :  요즘 같이 개 , 고양이 반려동물 문화 가 잘 돼있는 시기 에 ... ㅠㅠ 그렇게 한남 들 이 좋던가요 ? 진짜 실망 을 넘어 분노합니다 . \n",
      "\n",
      "\n",
      "95\n",
      "원본 :  허안나씨 진짜 예전부터 예쁘다고 생각했어요 축하드립니다 \n",
      "okt :  허안나 씨 진짜 예전 부터 예쁘다고 생각 했어요 축하 드립니다 \n",
      "\n",
      "\n",
      "96\n",
      "원본 :  사실 개그맨이라서 그런거지 미인이고 글래머이심 멋진 여성이심 \n",
      "okt :  사실 개그맨 이라서 그런 거지 미인 이고 글래머 이심 멋진 여성 이심 \n",
      "\n",
      "\n",
      "97\n",
      "원본 :  사진을 너무 못찍는다 \n",
      "okt :  사진 을 너무 못 찍는다 \n",
      "\n",
      "\n",
      "98\n",
      "원본 :  얼굴에 칼댔네 \n",
      "okt :  얼굴 에 칼 댔네 \n",
      "\n",
      "\n",
      "99\n",
      "원본 :  개콘의 장대인데 장도연에 캐릭터묻힌 안나씨ㅠ뜨길바랄게요 \n",
      "okt :  개콘 의 장대 인데 장도연 에 캐릭터 묻힌 안나 씨 ㅠ 뜨길 바랄게요 \n",
      "\n",
      "\n",
      "100\n",
      "원본 :  이여자분 누군지모르겠는데 콧구멍이 돼지같냐 \n",
      "okt :  이 여자 분 누군지 모르겠는데 콧구멍 이 돼지 같냐 \n",
      "\n",
      "\n",
      "101\n",
      "원본 :  그러고 보니 개그맨,개그우먼들이 잘사귀다 결혼하고 또 오랬동안 트러블? 없이 잘사네 \n",
      "okt :  그러고 보니 개그맨 , 개그우먼 들 이 잘 사귀다 결혼 하고 또 오 랬 동안 트러블 ? 없이 잘 사네 \n",
      "\n",
      "\n",
      "102\n",
      "원본 :  유튜브 잘보고있습니다!! 행복하세요~ \n",
      "okt :  유튜브 잘 보고있습니다 !! 행복하세요 ~ \n",
      "\n",
      "\n",
      "103\n",
      "원본 :  마음놓고 한댄다 하이고 \n",
      "okt :  마음 놓고 한 댄다 하이고 \n",
      "\n",
      "\n",
      "104\n",
      "원본 :  강용석의 가로세로 연구소에서 한효주 정확히 아니라고 언급했어요~ \n",
      "okt :  강용석 의 가로세로 연구소 에서 한효주 정확히 아니라고 언급 했어요 ~ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dif_idx = test[test.comments != test.okt].index\n",
    "print(len(dif_idx))\n",
    "for idx in dif_idx[49:100]:\n",
    "    print(idx)\n",
    "    print('원본 : ', test['comments'][idx],'\\nokt : ', test['okt'][idx], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw vs 반복제거 vs okt\n",
      "\n",
      "---- 원본 ----\n",
      "작업물도 잘 안내는데 그놈의 랩퍼딱지는 ㅋㅋㅋㅋㅋㅋㅋㅋ\n",
      "\n",
      "---- 반복 제거 적용 후 ----\n",
      "작업물도 잘 안내는데 그놈의 랩퍼딱지는 ㅋㅋ\n",
      "\n",
      "---- OKT 적용 후 ----\n",
      "작업 물 도 잘 안내는데 그 놈 의 랩퍼 딱지 는 ㅋㅋㅋㅋㅋㅋㅋㅋ\n",
      "\n",
      "---- maxscore_tokenizer ----\n",
      "작업물도 잘 안내는데 그놈의 랩퍼딱지는 ㅋㅋㅋㅋㅋㅋㅋㅋ\n",
      "\n",
      "---- OKT - 반복제거 ----\n",
      "작업 물 도 잘 안내는데 그 놈 의 랩퍼 딱지 는 ㅋㅋ\n",
      "\n",
      "---- 반복제거 - OKT ----\n",
      "작업 물 도 잘 안내는데 그 놈 의 랩퍼 딱지 는 ㅋㅋ\n",
      "\n",
      "---- OKT - maxscore_tokenizer ----\n",
      "작업 물 도 잘 안내는데 그 놈 의 랩퍼 딱지 는 ㅋㅋㅋㅋㅋㅋㅋㅋ\n"
     ]
    }
   ],
   "source": [
    "sample = X[dif_idx[25]]\n",
    "\n",
    "print('raw vs 반복제거 vs okt\\n')\n",
    "print('---- 원본 ----')\n",
    "print(sample)\n",
    "\n",
    "print('\\n---- 반복 제거 적용 후 ----')\n",
    "repeat = repeat_normalize(sample, num_repeats=2)\n",
    "print(repeat)\n",
    "\n",
    "print('\\n---- OKT 적용 후 ----')\n",
    "test = ' '.join(okt.morphs(sample))\n",
    "print(test)\n",
    "\n",
    "print('\\n---- maxscore_tokenizer ----')\n",
    "print(' '.join(maxscore_tokenizer.tokenize(sample)) )\n",
    "\n",
    "print('\\n---- OKT - 반복제거 ----')\n",
    "print(repeat_normalize(test, num_repeats=2))\n",
    "\n",
    "print('\\n---- 반복제거 - OKT ----')\n",
    "print(' '.join(okt.morphs(repeat)))\n",
    "\n",
    "print('\\n---- OKT - maxscore_tokenizer ----')\n",
    "print(' '.join(maxscore_tokenizer.tokenize(test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다시 전처리\n",
    "- soynlp로 전처리\n",
    "    - DoublespaceLineCorpus\n",
    "    - WordExtractor\n",
    "    - 띄어쓰기가 잘 되어 있는 경우: L-토큰화\n",
    "    - 띄어쓰기가 안되어 있는 경우: Max Score 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt_ls = []\n",
    "for c in X:\n",
    "    okt_ls.append(' '.join(okt.morphs(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한남 이지만 명복 은 빌어 드릴께요 ....',\n",
       " '울지마 바보 야 ... 나 정말 갠차나',\n",
       " '결혼 까지 생각 했어 같은 집 같 은방 에서 슬퍼도 bye bye bye ~~~~#',\n",
       " '에이미 물귀신 작전 이 휘 ( 발 ) 성 이벤트 면 좋겠는데 ...',\n",
       " '아무튼 여자 조심하자 한순간 에 인생 쫑 난 다',\n",
       " '케이윌 목소리 나 창법 너무 올 드하 지 않나 콘서트 도 하네',\n",
       " '에이미 제발 조용히 사세요 .. 다른 사람 에게 피 해주지마라 .. 너 로 인하여 아무 이유 없이 피 해보게 하지마 .. 재수앖 네',\n",
       " '이래서 여자 는 상종 하면 안 돼 ..... 시기 질투 ... 이제 와 서 ㅈㄹ 이야 ... 안고가기로 했으면 잘살게 내버려 두지 ...',\n",
       " '에이미 .. 넘 이상한것 같음 ..',\n",
       " '우리 화사 언 냐 는 걸 크지만 저 효린 은 여우 짓 이라구 욧 !!!!']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_ls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.591 Gbry 0.574 Gb\n",
      "all cohesion probabilities was computed. # words = 111\n",
      "all branching entropies was computed # words = 7463\n",
      "all accessor variety was computed # words = 7463\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "\n",
    "word_extractor = WordExtractor(\n",
    "    min_frequency=100, # example\n",
    "    min_cohesion_forward=0.05,\n",
    "    min_right_branching_entropy=0.0\n",
    ")\n",
    "\n",
    "word_extractor.train(X)\n",
    "words = word_extractor.extract()\n",
    "cohesion_score = {word:score.cohesion_forward for word, score in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교\n",
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "maxscore_tokenizer = MaxScoreTokenizer(scores=cohesion_score)\n",
    "ls = []\n",
    "for c in X:\n",
    "    #c = repeat_normalize(c, num_repeats=2)\n",
    "    ment = ' '.join(maxscore_tokenizer.tokenize(c)) \n",
    "    ls.append(ment)\n",
    "test['max'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>soynlp</th>\n",
       "      <th>okt</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한남이지만 명복은 빌어드릴께요....</td>\n",
       "      <td>한남이지만 명복은 빌어드릴께요....</td>\n",
       "      <td>한남 이지만 명복 은 빌어 드릴께요 ....</td>\n",
       "      <td>한남이지만 명복은 빌어드릴께요 .. ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>울지마 바보야...나 정말 갠차나</td>\n",
       "      <td>울지마 바보야...나 정말 갠차나</td>\n",
       "      <td>울지마 바보 야 ... 나 정말 갠차나</td>\n",
       "      <td>울지마 바보야 .. .나 정말 갠차나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>결혼까지 생각했어 같은집 같은방에서 슬퍼도 bye bye bye~~~~#</td>\n",
       "      <td>결혼까지 생각했어 같은집 같은방에서 슬퍼도 bye bye bye~~~~#</td>\n",
       "      <td>결혼 까지 생각 했어 같은 집 같 은방 에서 슬퍼도 bye bye bye ~~~~#</td>\n",
       "      <td>결혼 까지 생각 했어 같은 집 같은 방에서 슬퍼도 bye bye bye~~~~#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>에이미 물귀신 작전이 휘(발)성 이벤트면 좋겠는데...</td>\n",
       "      <td>에이미 물귀신 작전이 휘(발)성 이벤트면 좋겠는데...</td>\n",
       "      <td>에이미 물귀신 작전 이 휘 ( 발 ) 성 이벤트 면 좋겠는데 ...</td>\n",
       "      <td>에이미 물귀신 작전이 휘(발)성 이벤트면 좋겠는데 .. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무튼 여자조심하자한순간에 인생쫑난다</td>\n",
       "      <td>아무튼 여자조심하자한순간에 인생쫑난다</td>\n",
       "      <td>아무튼 여자 조심하자 한순간 에 인생 쫑 난 다</td>\n",
       "      <td>아무튼 여자 조심하자한순간에 인생쫑난다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7888</th>\n",
       "      <td>프듀출신이면 롤모델로 워너원 말했어야지 요즘 더 잘나가는 것도 워너원이고</td>\n",
       "      <td>프듀출신이면 롤모델로 워너원 말했어야지 요즘 더 잘나가는 것도 워너원이고</td>\n",
       "      <td>프듀 출신 이 면 롤모델 로 워 너 원 말 했어야지 요즘 더 잘나가는 것 도 워 너...</td>\n",
       "      <td>프듀출신이면 롤모델로 워너원 말했어야지 요즘 더 잘나가는 것도 워너원이고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7889</th>\n",
       "      <td>10년차방탄팬인데 우리방탄처럼 성공은못하겠지만 일단 방탄의 부하가되고싶다는거니 이름...</td>\n",
       "      <td>10년차방탄팬인데 우리방탄처럼 성공은못하겠지만 일단 방탄의 부하가되고싶다는거니 이름...</td>\n",
       "      <td>10년 차방탄팬인데 우리 방탄 처럼 성공 은 못 하겠지만 일단 방탄 의 부하 가 되...</td>\n",
       "      <td>10년차방탄팬인데 우리방탄처럼 성공은못하겠지만 일단 방탄의 부하가되고싶다는거니 이름...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>엑소는 범접할 수 없는 아이돌계의 신같은 존재라 감히 말도 못꺼내고, 그나마 방탄은...</td>\n",
       "      <td>엑소는 범접할 수 없는 아이돌계의 신같은 존재라 감히 말도 못꺼내고, 그나마 방탄은...</td>\n",
       "      <td>엑소 는 범접 할 수 없는 아이돌 계 의 신 같은 존재 라 감히 말 도 못 꺼내고 ...</td>\n",
       "      <td>엑소는 범접할 수 없는 아이 돌계의 신 같은 존재라 감히 말도 못꺼내고, 그나마 방...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>워너원이 나와야지. .</td>\n",
       "      <td>워너원이 나와야지. .</td>\n",
       "      <td>워 너 원 이 나와야지 . .</td>\n",
       "      <td>워너원이 나와야지. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>방탄이 롤모델이면 엑소에 밀려 계속 2인자로 남을텐데??</td>\n",
       "      <td>방탄이 롤모델이면 엑소에 밀려 계속 2인자로 남을텐데??</td>\n",
       "      <td>방탄 이 롤모델 이면 엑소 에 밀려 계속 2 인자 로 남을텐데 ??</td>\n",
       "      <td>방탄이 롤모델이면 엑소에 밀려 계속 2인자로 남을텐데??</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7893 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comments  \\\n",
       "0                                  한남이지만 명복은 빌어드릴께요....   \n",
       "1                                    울지마 바보야...나 정말 갠차나   \n",
       "2              결혼까지 생각했어 같은집 같은방에서 슬퍼도 bye bye bye~~~~#   \n",
       "3                        에이미 물귀신 작전이 휘(발)성 이벤트면 좋겠는데...   \n",
       "4                                  아무튼 여자조심하자한순간에 인생쫑난다   \n",
       "...                                                 ...   \n",
       "7888           프듀출신이면 롤모델로 워너원 말했어야지 요즘 더 잘나가는 것도 워너원이고   \n",
       "7889  10년차방탄팬인데 우리방탄처럼 성공은못하겠지만 일단 방탄의 부하가되고싶다는거니 이름...   \n",
       "7890  엑소는 범접할 수 없는 아이돌계의 신같은 존재라 감히 말도 못꺼내고, 그나마 방탄은...   \n",
       "7891                                       워너원이 나와야지. .   \n",
       "7892                    방탄이 롤모델이면 엑소에 밀려 계속 2인자로 남을텐데??   \n",
       "\n",
       "                                                 soynlp  \\\n",
       "0                                  한남이지만 명복은 빌어드릴께요....   \n",
       "1                                    울지마 바보야...나 정말 갠차나   \n",
       "2              결혼까지 생각했어 같은집 같은방에서 슬퍼도 bye bye bye~~~~#   \n",
       "3                        에이미 물귀신 작전이 휘(발)성 이벤트면 좋겠는데...   \n",
       "4                                  아무튼 여자조심하자한순간에 인생쫑난다   \n",
       "...                                                 ...   \n",
       "7888           프듀출신이면 롤모델로 워너원 말했어야지 요즘 더 잘나가는 것도 워너원이고   \n",
       "7889  10년차방탄팬인데 우리방탄처럼 성공은못하겠지만 일단 방탄의 부하가되고싶다는거니 이름...   \n",
       "7890  엑소는 범접할 수 없는 아이돌계의 신같은 존재라 감히 말도 못꺼내고, 그나마 방탄은...   \n",
       "7891                                       워너원이 나와야지. .   \n",
       "7892                    방탄이 롤모델이면 엑소에 밀려 계속 2인자로 남을텐데??   \n",
       "\n",
       "                                                    okt  \\\n",
       "0                              한남 이지만 명복 은 빌어 드릴께요 ....   \n",
       "1                                 울지마 바보 야 ... 나 정말 갠차나   \n",
       "2        결혼 까지 생각 했어 같은 집 같 은방 에서 슬퍼도 bye bye bye ~~~~#   \n",
       "3                 에이미 물귀신 작전 이 휘 ( 발 ) 성 이벤트 면 좋겠는데 ...   \n",
       "4                            아무튼 여자 조심하자 한순간 에 인생 쫑 난 다   \n",
       "...                                                 ...   \n",
       "7888  프듀 출신 이 면 롤모델 로 워 너 원 말 했어야지 요즘 더 잘나가는 것 도 워 너...   \n",
       "7889  10년 차방탄팬인데 우리 방탄 처럼 성공 은 못 하겠지만 일단 방탄 의 부하 가 되...   \n",
       "7890  엑소 는 범접 할 수 없는 아이돌 계 의 신 같은 존재 라 감히 말 도 못 꺼내고 ...   \n",
       "7891                                   워 너 원 이 나와야지 . .   \n",
       "7892              방탄 이 롤모델 이면 엑소 에 밀려 계속 2 인자 로 남을텐데 ??   \n",
       "\n",
       "                                                    max  \n",
       "0                                한남이지만 명복은 빌어드릴께요 .. ..  \n",
       "1                                  울지마 바보야 .. .나 정말 갠차나  \n",
       "2          결혼 까지 생각 했어 같은 집 같은 방에서 슬퍼도 bye bye bye~~~~#  \n",
       "3                      에이미 물귀신 작전이 휘(발)성 이벤트면 좋겠는데 .. .  \n",
       "4                                 아무튼 여자 조심하자한순간에 인생쫑난다  \n",
       "...                                                 ...  \n",
       "7888           프듀출신이면 롤모델로 워너원 말했어야지 요즘 더 잘나가는 것도 워너원이고  \n",
       "7889  10년차방탄팬인데 우리방탄처럼 성공은못하겠지만 일단 방탄의 부하가되고싶다는거니 이름...  \n",
       "7890  엑소는 범접할 수 없는 아이 돌계의 신 같은 존재라 감히 말도 못꺼내고, 그나마 방...  \n",
       "7891                                       워너원이 나와야지. .  \n",
       "7892                    방탄이 롤모델이면 엑소에 밀려 계속 2인자로 남을텐데??  \n",
       "\n",
       "[7893 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5395\n",
      "0\n",
      "원본 :  한남이지만 명복은 빌어드릴께요.... \n",
      "max :  한남이지만 명복은 빌어드릴께요 .. .. \n",
      "\n",
      "\n",
      "1\n",
      "원본 :  울지마 바보야...나 정말 갠차나 \n",
      "max :  울지마 바보야 .. .나 정말 갠차나 \n",
      "\n",
      "\n",
      "2\n",
      "원본 :  결혼까지 생각했어 같은집 같은방에서 슬퍼도 bye bye bye~~~~# \n",
      "max :  결혼 까지 생각 했어 같은 집 같은 방에서 슬퍼도 bye bye bye~~~~# \n",
      "\n",
      "\n",
      "3\n",
      "원본 :  에이미 물귀신 작전이 휘(발)성 이벤트면 좋겠는데... \n",
      "max :  에이미 물귀신 작전이 휘(발)성 이벤트면 좋겠는데 .. . \n",
      "\n",
      "\n",
      "4\n",
      "원본 :  아무튼 여자조심하자한순간에 인생쫑난다 \n",
      "max :  아무튼 여자 조심하자한순간에 인생쫑난다 \n",
      "\n",
      "\n",
      "5\n",
      "원본 :  케이윌 목소리나 창법 너무 올드하지않나 콘서트도 하네 \n",
      "max :  케이윌 목소리나 창법 너무 올드 하지 않나 콘서트도 하네 \n",
      "\n",
      "\n",
      "6\n",
      "원본 :  에이미 제발 조용히 사세요..다른 사람에게 피해주지마라..너로 인하여 아무 이유없이 피해보게 하지마..재수앖네 \n",
      "max :  에이미 제발 조용히 사세요 .. 다른 사람 에게 피해주지마라 .. 너로 인하여 아무 이유없이 피해보게 하지 마 .. 재수앖네 \n",
      "\n",
      "\n",
      "7\n",
      "원본 :  이래서 여자는 상종하면 안돼.....시기 질투...이제와서 ㅈㄹ 이야...안고가기로했으면 잘살게 내버려두지... \n",
      "max :  이래서 여자 는 상종하면 안돼 .. .. .시기 질투 .. . 이제 와서 ㅈㄹ 이야 .. .안고가기로했으면 잘살게 내버려두지 .. . \n",
      "\n",
      "\n",
      "8\n",
      "원본 :  에이미.. 넘 이상한것 같음.. \n",
      "max :  에이미 .. 넘 이상한것 같음 .. \n",
      "\n",
      "\n",
      "9\n",
      "원본 :  우리 화사언냐는 걸크지만 저 효린은 여우짓이라구욧!!!! \n",
      "max :  우리 화사언냐는 걸크지만 저 효린은 여우짓이라구욧!!! ! \n",
      "\n",
      "\n",
      "10\n",
      "원본 :  얼마나 압도했으면 이런 기사도 나왔겠어ㅋ효린 이쁘기만하구만 연예대상 측도 효린이 이런 스타일의 무대하는 거를 몰라서 불렀겠냐아침부터 왜들 유난인지 어휴 \n",
      "max :  얼마 나 압도했으면 이런 기사 도 나왔겠어ㅋ효린 이쁘 기만하구만 연예 대상 측도 효린이 이런 스타일의 무대 하는 거를 몰라서 불렀겠냐아침부터 왜들 유난인지 어휴 \n",
      "\n",
      "\n",
      "11\n",
      "원본 :  통장에 십원밖에 없나? 시집가고 드라마도 안팔리고 .어쩌누 \n",
      "max :  통장에 십원밖에 없나? 시집가고 드라마 도 안팔리고 .어쩌누 \n",
      "\n",
      "\n",
      "12\n",
      "원본 :  제발 연기 연습좀 하고 나오세요.. \n",
      "max :  제발 연기 연습좀 하고 나오 세요 .. \n",
      "\n",
      "\n",
      "13\n",
      "원본 :  결혼하고 인기급하락....왜지??? \n",
      "max :  결혼 하고 인기급하락 .. .. 왜지??? \n",
      "\n",
      "\n",
      "14\n",
      "원본 :  누구.....배우인가요? 가수인가요?? \n",
      "max :  누구 .. .. . 배우 인가요? 가수인가요?? \n",
      "\n",
      "\n",
      "15\n",
      "원본 :  와 40대 여자를 누가 데려갔지;;; \n",
      "max :  와 40대 여자 를 누가 데려갔지;;; \n",
      "\n",
      "\n",
      "18\n",
      "원본 :  엄마가 황신혜인데 구찌 옷이 대수겠냐. 이쁘다~ \n",
      "max :  엄마가 황신혜인데 구찌 옷이 대수겠냐. 이쁘 다~ \n",
      "\n",
      "\n",
      "20\n",
      "원본 :  명품옷이라도 저렇게 전체적으로 로고가 다 디자인 된 옷은 너무 촌스럽지 않나요? 저런옷은 왠지 입기 챙피할거 같은데 \n",
      "max :  명품옷이라도 저렇게 전체적으로 로고가 다 디자인 된 옷은 너무 촌스럽지 않나요? 저런옷은 왠지 입기 챙피할거 같은 데 \n",
      "\n",
      "\n",
      "21\n",
      "원본 :  기자앙반아 명품이란말 올려놓구 착한 이진이 뭔잘못이 있다고욕을먹게하냐? 실수했다기레기야 \n",
      "max :  기자앙반아 명품이란말 올려놓구 착한 이진이 뭔 잘못 이 있다고욕을먹게하냐? 실수했다기레기야 \n",
      "\n",
      "\n",
      "22\n",
      "원본 :  논란은 늘 이런 기사의 제목이 한 몫 하는 듯!돈 많은 사람들은 돈을 써야 경제가 돌아가죠 명품을 입든말든~ 이런 제목 진짜 별루에요..ㅡㅡ \n",
      "max :  논란은 늘 이런 기사 의 제목이 한 몫 하는 듯!돈 많은 사람 들은 돈을 써야 경제가 돌아가죠 명품을 입든말든~ 이런 제목 진짜 별루에요 .. ㅡㅡ \n",
      "\n",
      "\n",
      "23\n",
      "원본 :  헤럴드 기자들은 이름을 안올리더라 굳이 명품이란 단어를 써야하나 머 질투라도 나는거처럼 기사를 쓰네 웃겨 \n",
      "max :  헤럴드 기자들은 이름을 안올리더라 굳이 명품이란 단어를 써야 하나 머 질투라도 나는거처럼 기사 를 쓰네 웃겨 \n",
      "\n",
      "\n",
      "24\n",
      "원본 :  어느정도 저분 말도 공감..근데 워낙 백종원 팬들이 많아서 대차게 욕먹으실듯..말 잘하시는 분이라 까이지는 않으실것같고 힘내세요~ \n",
      "max :  어느정도 저분 말도 공감 .. 근데 워낙 백종원 팬들이 많아서 대차게 욕먹으실듯 .. 말 잘하시는 분이라 까이지는 않으실것같고 힘내세요~ \n",
      "\n",
      "\n",
      "27\n",
      "원본 :  미디어가 한명의 음식평론가 욕심쟁이 꼰대로 만드는 거 순식간이네 역시 언론은 무서워 ..... \n",
      "max :  미디어가 한명의 음식평론가 욕심쟁이 꼰대로 만드는 거 순식간이네 역시 언론은 무서워 .. .. . \n",
      "\n",
      "\n",
      "28\n",
      "원본 :  개돼지 네티즌은 무었이 진실인지는 중요하지 않고 니편 내편이 중요한거지. 음식에 이념을 갖다 붙이고 비판하는 넘들 진짜 한심한 부류들... \n",
      "max :  개돼지 네티즌은 무었이 진실인지는 중요 하지 않고 니편 내편이 중요한거지. 음식에 이념을 갖다 붙이고 비판 하는 넘들 진짜 한심한 부류들 .. . \n",
      "\n",
      "\n",
      "29\n",
      "원본 :  서민들 장사하는 사람 백종원 욕하는 사람 엄청 많습니다 ㆍ \n",
      "max :  서민들 장사 하는 사람 백종원 욕 하는 사람 엄청 많습니다 ㆍ \n",
      "\n",
      "\n",
      "33\n",
      "원본 :  난 언니도 재미있구 둘이 티격태격 하는것도 재미있던데..왜들 그러냐 \n",
      "max :  난 언니도 재미 있구 둘이 티격태격 하는 것도 재미 있던데 .. 왜들 그러냐 \n",
      "\n",
      "\n",
      "35\n",
      "원본 :  정말 이런건 안올리면 좋겠음 정말 가고픈이들도 많을텐데 능력이안돼 못가면 얼마나 자괴감들겠어 응 누가 궁금하다고 \n",
      "max :  정말 이런 건 안올리면 좋겠음 정말 가고픈이들도 많을텐데 능력이안돼 못가면 얼마 나 자괴감들겠어 응 누가 궁금하다고 \n",
      "\n",
      "\n",
      "36\n",
      "원본 :  순간 홍진영으로 보고 홍진영 숨겨진 딸이 있었나 했음... \n",
      "max :  순간 홍진영으로 보고 홍진영 숨겨진 딸이 있었나 했음 .. . \n",
      "\n",
      "\n",
      "37\n",
      "원본 :  홍진경씨 머리왜저럼? 탈코르셋임? 예쁜애들이 탈코르셋하는건 본적이없네. \n",
      "max :  홍진경씨 머리왜저럼? 탈코르셋임? 예쁜애들이 탈코르셋 하는 건 본적이없네. \n",
      "\n",
      "\n",
      "38\n",
      "원본 :  난민같음 ㅋㅋㅋㅋ \n",
      "max :  난민같음 ㅋㅋ ㅋㅋ \n",
      "\n",
      "\n",
      "42\n",
      "원본 :  홍자가 그말을 진심으로 했다는 식으로 몰아가네...?!전라도는 상종을 못할 인갈들. \n",
      "max :  홍자가 그말을 진심으로 했다는 식으로 몰아가네 .. .?!전라도는 상종을 못할 인갈들. \n",
      "\n",
      "\n",
      "43\n",
      "원본 :  그냥 전라도사람들이 예민한듯 저발언을 부산에서 했다생각해봐 그냥 웃어 넘겼음 \n",
      "max :  그냥 전라도 사람 들이 예민한듯 저발언을 부산에서 했다 생각 해봐 그냥 웃어 넘겼음 \n",
      "\n",
      "\n",
      "44\n",
      "원본 :  맞는말인데 ㅋㅋㅋ 전라디언들은 그들만의 세상에 살잖아?? 통수 잘치고 ㅋ \n",
      "max :  맞는말인데 ㅋㅋ ㅋ 전라디언들은 그들만의 세상에 살잖아?? 통수 잘치고 ㅋ \n",
      "\n",
      "\n",
      "46\n",
      "원본 :  홍자매 재밌기만하던데ᆢ 왜 안티들이 있는지ᆢ보다가 체널 돌리면되요ᆢ요즘 일반인들도 성형하는데ᆢ어제 홍진영짜장면~~완전 ㅋㅋ \n",
      "max :  홍자매 재밌기만하던데ᆢ 왜 안티들이 있는 지ᆢ보다가 체널 돌리면되요ᆢ요즘 일반인들도 성형 하는 데ᆢ어제 홍진영짜장면~~완전 ㅋㅋ \n",
      "\n",
      "\n",
      "48\n",
      "원본 :  둘이 소속사까지.... 두 커플 응원하긴 한다만 나중에 헤어지면 어쩌려고 \n",
      "max :  둘이 소속사까지 .. .. 두 커플 응원 하긴 한다만 나중에 헤어지면 어쩌려고 \n",
      "\n",
      "\n",
      "49\n",
      "원본 :  너무 싸보이는 느낌..살려고 발버둥치는것 같긴한데...좀 안타깝군요싸이는 어쩔려고... \n",
      "max :  너무 싸보이는 느낌 .. 살려고 발버둥치는것 같긴한데 .. .좀 안타깝군요싸이는 어쩔려고 .. . \n",
      "\n",
      "\n",
      "50\n",
      "원본 :  어우 난 남잔데..저리 마른여자는 좀 징그럽더라 살좀있는여자가 건강미있어보이고 좋음 \n",
      "max :  어우 난 남잔데 .. 저리 마른 여자 는 좀 징그럽더라 살좀 있는 여자 가 건강미있어보이고 좋음 \n",
      "\n",
      "\n",
      "51\n",
      "원본 :  태국 가서 머했을까...궁금궁금 \n",
      "max :  태국 가서 머했을까 .. .궁금궁금 \n",
      "\n",
      "\n",
      "53\n",
      "원본 :  솔직히 내가 연예인 메이크업하고 옷 좀 걸치면 이던이 정도는 가뿐할듯 \n",
      "max :  솔직 히 내가 연예인 메이크업하고 옷 좀 걸치면 이던이 정도는 가뿐할듯 \n",
      "\n",
      "\n",
      "54\n",
      "원본 :  회사짤려 욕쳐먹어 쫌있음 개인스케줄 만남소원해져서 이별 할거뻔하고 저것들이 가수냐 댄서지 댄서들 끝은 99프로 새드앤딩 그리고 철이없어도 너무없다 \n",
      "max :  회사짤려 욕쳐먹어 쫌있음 개인스케줄 만남소원해져서 이별 할거뻔하고 저것들이 가수냐 댄서지 댄서들 끝은 99프로 새드앤딩 그리고 철이없어도 너무 없다 \n",
      "\n",
      "\n",
      "55\n",
      "원본 :  얘네 근데 너무 오바들 떨긴하네 ㅋㅋㅋ 이해가 간다 소속사가 슬슬 \n",
      "max :  얘네 근데 너무 오바들 떨긴하네 ㅋㅋ ㅋ 이해가 간다 소속사가 슬슬 \n",
      "\n",
      "\n",
      "57\n",
      "원본 :  이런 걸 왜 찍는걸까? 성관계 동영상 찍는 거랑 같은 거 아닌가? \n",
      "max :  이런 걸 왜 찍는걸까? 성관계 동영상 찍는 거랑 같은 거 아닌 가? \n",
      "\n",
      "\n",
      "58\n",
      "원본 :  멋있기만 하구만.이러다 헤어지면 헤어지는거지뭐.연예할때 맘껏 즐기는거 보기 좋은데.내숭보단 훨씬 낫다.화이팅!! \n",
      "max :  멋있기만 하구만.이러다 헤어지면 헤어지는거지뭐. 연예 할때 맘껏 즐기는거 보기 좋은 데.내숭보단 훨씬 낫다.화이팅!! \n",
      "\n",
      "\n",
      "60\n",
      "원본 :  ㅋㅋㅋ 생각이라는 걸 하고 산다면...ㅋㅋㅋㅋ \n",
      "max :  ㅋㅋ ㅋ 생각 이라는 걸 하고 산다면 .. . ㅋㅋ ㅋㅋ \n",
      "\n",
      "\n",
      "62\n",
      "원본 :  나이조어린것들이 병이 왜캐많어 빠져갖고 \n",
      "max :  나이 조어린것들이 병이 왜캐많어 빠져갖고 \n",
      "\n",
      "\n",
      "64\n",
      "원본 :  프로다운대처는 무슨..그러고 돌아다니면 애들이 따라한다 행실을 똑바로해라.. \n",
      "max :  프로다운대처는 무슨 .. 그러고 돌아다니면 애들이 따라한다 행실을 똑바로해라 .. \n",
      "\n",
      "\n",
      "65\n",
      "원본 :  화나요는 다 여자가누른듯, , ,,인정하면 up, , , \n",
      "max :  화나요는 다 여자 가누른듯, , ,,인정하면 up, , , \n",
      "\n",
      "\n",
      "66\n",
      "원본 :  ㅇㅅㅇ 여자들은 싫어합니다 \n",
      "max :  ㅇㅅㅇ 여자 들은 싫어합니다 \n",
      "\n",
      "\n",
      "68\n",
      "원본 :  그걸 즐기는 거면 할 말은 없다만~ ㅋㅋㅋㅋ 같은 저러는 거 이해가 안 되긴 함 ㅋㅋㅋㅋㅋㅋ \n",
      "max :  그걸 즐기는 거면 할 말은 없다만~ ㅋㅋ ㅋㅋ 같은 저러는 거 이해가 안 되긴 함 ㅋㅋ ㅋㅋ ㅋㅋ \n",
      "\n",
      "\n",
      "71\n",
      "원본 :  한때나마 내가 예진이를 좋아했다는게 너무 창피하다 ㅠ 아줌마 예진이... 이건 아니거던... 아... 나 엄청 챙피 꽥하고파 ㅠ \n",
      "max :  한때나마 내가 예진이를 좋아 했다는게 너무 창피하다 ㅠ 아줌마 예진이 .. . 이건 아니 거던 .. . 아 .. . 나 엄청 챙피 꽥하고파 ㅠ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dif_idx2 = test[test['comments'] != test['max']].index\n",
    "print(len(dif_idx2))\n",
    "for idx in dif_idx2[0:50]:\n",
    "    print(idx)\n",
    "    print('원본 : ', test['comments'][idx],'\\nmax : ', test['max'][idx], '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.tokenizer import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "ls = []\n",
    "for c in X:\n",
    "    #c = repeat_normalize(c, num_repeats=2)\n",
    "    ment = ' '.join(tokenizer.tokenize(c)) \n",
    "    ls.append(ment)\n",
    "test['reg'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5253\n",
      "0\n",
      "원본 :  한남이지만 명복은 빌어드릴께요.... \n",
      "max :  한남이지만 명복은 빌어드릴께요 .... \n",
      "\n",
      "\n",
      "1\n",
      "원본 :  울지마 바보야...나 정말 갠차나 \n",
      "max :  울지마 바보야 ... 나 정말 갠차나 \n",
      "\n",
      "\n",
      "2\n",
      "원본 :  결혼까지 생각했어 같은집 같은방에서 슬퍼도 bye bye bye~~~~# \n",
      "max :  결혼까지 생각했어 같은집 같은방에서 슬퍼도 bye bye bye ~~~~# \n",
      "\n",
      "\n",
      "3\n",
      "원본 :  에이미 물귀신 작전이 휘(발)성 이벤트면 좋겠는데... \n",
      "max :  에이미 물귀신 작전이 휘 ( 발 ) 성 이벤트면 좋겠는데 ... \n",
      "\n",
      "\n",
      "6\n",
      "원본 :  에이미 제발 조용히 사세요..다른 사람에게 피해주지마라..너로 인하여 아무 이유없이 피해보게 하지마..재수앖네 \n",
      "max :  에이미 제발 조용히 사세요 .. 다른 사람에게 피해주지마라 .. 너로 인하여 아무 이유없이 피해보게 하지마 .. 재수앖네 \n",
      "\n",
      "\n",
      "7\n",
      "원본 :  이래서 여자는 상종하면 안돼.....시기 질투...이제와서 ㅈㄹ 이야...안고가기로했으면 잘살게 내버려두지... \n",
      "max :  이래서 여자는 상종하면 안돼 ..... 시기 질투 ... 이제와서 ㅈㄹ 이야 ... 안고가기로했으면 잘살게 내버려두지 ... \n",
      "\n",
      "\n",
      "8\n",
      "원본 :  에이미.. 넘 이상한것 같음.. \n",
      "max :  에이미 .. 넘 이상한것 같음 .. \n",
      "\n",
      "\n",
      "9\n",
      "원본 :  우리 화사언냐는 걸크지만 저 효린은 여우짓이라구욧!!!! \n",
      "max :  우리 화사언냐는 걸크지만 저 효린은 여우짓이라구욧 !!!! \n",
      "\n",
      "\n",
      "10\n",
      "원본 :  얼마나 압도했으면 이런 기사도 나왔겠어ㅋ효린 이쁘기만하구만 연예대상 측도 효린이 이런 스타일의 무대하는 거를 몰라서 불렀겠냐아침부터 왜들 유난인지 어휴 \n",
      "max :  얼마나 압도했으면 이런 기사도 나왔겠어 ㅋ 효린 이쁘기만하구만 연예대상 측도 효린이 이런 스타일의 무대하는 거를 몰라서 불렀겠냐아침부터 왜들 유난인지 어휴 \n",
      "\n",
      "\n",
      "11\n",
      "원본 :  통장에 십원밖에 없나? 시집가고 드라마도 안팔리고 .어쩌누 \n",
      "max :  통장에 십원밖에 없나 ? 시집가고 드라마도 안팔리고 . 어쩌누 \n",
      "\n",
      "\n",
      "12\n",
      "원본 :  제발 연기 연습좀 하고 나오세요.. \n",
      "max :  제발 연기 연습좀 하고 나오세요 .. \n",
      "\n",
      "\n",
      "13\n",
      "원본 :  결혼하고 인기급하락....왜지??? \n",
      "max :  결혼하고 인기급하락 .... 왜지 ??? \n",
      "\n",
      "\n",
      "14\n",
      "원본 :  누구.....배우인가요? 가수인가요?? \n",
      "max :  누구 ..... 배우인가요 ? 가수인가요 ?? \n",
      "\n",
      "\n",
      "15\n",
      "원본 :  와 40대 여자를 누가 데려갔지;;; \n",
      "max :  와 40 대 여자를 누가 데려갔지 ;;; \n",
      "\n",
      "\n",
      "18\n",
      "원본 :  엄마가 황신혜인데 구찌 옷이 대수겠냐. 이쁘다~ \n",
      "max :  엄마가 황신혜인데 구찌 옷이 대수겠냐 . 이쁘다 ~ \n",
      "\n",
      "\n",
      "19\n",
      "원본 :  제목 무엇??? \n",
      "max :  제목 무엇 ??? \n",
      "\n",
      "\n",
      "20\n",
      "원본 :  명품옷이라도 저렇게 전체적으로 로고가 다 디자인 된 옷은 너무 촌스럽지 않나요? 저런옷은 왠지 입기 챙피할거 같은데 \n",
      "max :  명품옷이라도 저렇게 전체적으로 로고가 다 디자인 된 옷은 너무 촌스럽지 않나요 ? 저런옷은 왠지 입기 챙피할거 같은데 \n",
      "\n",
      "\n",
      "21\n",
      "원본 :  기자앙반아 명품이란말 올려놓구 착한 이진이 뭔잘못이 있다고욕을먹게하냐? 실수했다기레기야 \n",
      "max :  기자앙반아 명품이란말 올려놓구 착한 이진이 뭔잘못이 있다고욕을먹게하냐 ? 실수했다기레기야 \n",
      "\n",
      "\n",
      "22\n",
      "원본 :  논란은 늘 이런 기사의 제목이 한 몫 하는 듯!돈 많은 사람들은 돈을 써야 경제가 돌아가죠 명품을 입든말든~ 이런 제목 진짜 별루에요..ㅡㅡ \n",
      "max :  논란은 늘 이런 기사의 제목이 한 몫 하는 듯 ! 돈 많은 사람들은 돈을 써야 경제가 돌아가죠 명품을 입든말든 ~ 이런 제목 진짜 별루에요 .. ㅡㅡ \n",
      "\n",
      "\n",
      "24\n",
      "원본 :  어느정도 저분 말도 공감..근데 워낙 백종원 팬들이 많아서 대차게 욕먹으실듯..말 잘하시는 분이라 까이지는 않으실것같고 힘내세요~ \n",
      "max :  어느정도 저분 말도 공감 .. 근데 워낙 백종원 팬들이 많아서 대차게 욕먹으실듯 .. 말 잘하시는 분이라 까이지는 않으실것같고 힘내세요 ~ \n",
      "\n",
      "\n",
      "28\n",
      "원본 :  개돼지 네티즌은 무었이 진실인지는 중요하지 않고 니편 내편이 중요한거지. 음식에 이념을 갖다 붙이고 비판하는 넘들 진짜 한심한 부류들... \n",
      "max :  개돼지 네티즌은 무었이 진실인지는 중요하지 않고 니편 내편이 중요한거지 . 음식에 이념을 갖다 붙이고 비판하는 넘들 진짜 한심한 부류들 ... \n",
      "\n",
      "\n",
      "32\n",
      "원본 :  열심히 사는데 예쁘게 봐 주십시다. 악플 그만 다시고. \n",
      "max :  열심히 사는데 예쁘게 봐 주십시다 . 악플 그만 다시고 . \n",
      "\n",
      "\n",
      "33\n",
      "원본 :  난 언니도 재미있구 둘이 티격태격 하는것도 재미있던데..왜들 그러냐 \n",
      "max :  난 언니도 재미있구 둘이 티격태격 하는것도 재미있던데 .. 왜들 그러냐 \n",
      "\n",
      "\n",
      "34\n",
      "원본 :  에이 뻥 아냐? \n",
      "max :  에이 뻥 아냐 ? \n",
      "\n",
      "\n",
      "36\n",
      "원본 :  순간 홍진영으로 보고 홍진영 숨겨진 딸이 있었나 했음... \n",
      "max :  순간 홍진영으로 보고 홍진영 숨겨진 딸이 있었나 했음 ... \n",
      "\n",
      "\n",
      "37\n",
      "원본 :  홍진경씨 머리왜저럼? 탈코르셋임? 예쁜애들이 탈코르셋하는건 본적이없네. \n",
      "max :  홍진경씨 머리왜저럼 ? 탈코르셋임 ? 예쁜애들이 탈코르셋하는건 본적이없네 . \n",
      "\n",
      "\n",
      "39\n",
      "원본 :  모델 같은 느끼 1도 안듬 \n",
      "max :  모델 같은 느끼 1 도 안듬 \n",
      "\n",
      "\n",
      "42\n",
      "원본 :  홍자가 그말을 진심으로 했다는 식으로 몰아가네...?!전라도는 상종을 못할 인갈들. \n",
      "max :  홍자가 그말을 진심으로 했다는 식으로 몰아가네 ...?! 전라도는 상종을 못할 인갈들 . \n",
      "\n",
      "\n",
      "44\n",
      "원본 :  맞는말인데 ㅋㅋㅋ 전라디언들은 그들만의 세상에 살잖아?? 통수 잘치고 ㅋ \n",
      "max :  맞는말인데 ㅋㅋㅋ 전라디언들은 그들만의 세상에 살잖아 ?? 통수 잘치고 ㅋ \n",
      "\n",
      "\n",
      "45\n",
      "원본 :  김종국 아빠 인생최대 행복했던 순간은 근육빵빵 아들내미 군대안갔을때? ㅎㅎ \n",
      "max :  김종국 아빠 인생최대 행복했던 순간은 근육빵빵 아들내미 군대안갔을때 ? ㅎㅎ \n",
      "\n",
      "\n",
      "46\n",
      "원본 :  홍자매 재밌기만하던데ᆢ 왜 안티들이 있는지ᆢ보다가 체널 돌리면되요ᆢ요즘 일반인들도 성형하는데ᆢ어제 홍진영짜장면~~완전 ㅋㅋ \n",
      "max :  홍자매 재밌기만하던데 ᆢ 왜 안티들이 있는지 ᆢ 보다가 체널 돌리면되요 ᆢ 요즘 일반인들도 성형하는데 ᆢ 어제 홍진영짜장면 ~~ 완전 ㅋㅋ \n",
      "\n",
      "\n",
      "48\n",
      "원본 :  둘이 소속사까지.... 두 커플 응원하긴 한다만 나중에 헤어지면 어쩌려고 \n",
      "max :  둘이 소속사까지 .... 두 커플 응원하긴 한다만 나중에 헤어지면 어쩌려고 \n",
      "\n",
      "\n",
      "49\n",
      "원본 :  너무 싸보이는 느낌..살려고 발버둥치는것 같긴한데...좀 안타깝군요싸이는 어쩔려고... \n",
      "max :  너무 싸보이는 느낌 .. 살려고 발버둥치는것 같긴한데 ... 좀 안타깝군요싸이는 어쩔려고 ... \n",
      "\n",
      "\n",
      "50\n",
      "원본 :  어우 난 남잔데..저리 마른여자는 좀 징그럽더라 살좀있는여자가 건강미있어보이고 좋음 \n",
      "max :  어우 난 남잔데 .. 저리 마른여자는 좀 징그럽더라 살좀있는여자가 건강미있어보이고 좋음 \n",
      "\n",
      "\n",
      "51\n",
      "원본 :  태국 가서 머했을까...궁금궁금 \n",
      "max :  태국 가서 머했을까 ... 궁금궁금 \n",
      "\n",
      "\n",
      "54\n",
      "원본 :  회사짤려 욕쳐먹어 쫌있음 개인스케줄 만남소원해져서 이별 할거뻔하고 저것들이 가수냐 댄서지 댄서들 끝은 99프로 새드앤딩 그리고 철이없어도 너무없다 \n",
      "max :  회사짤려 욕쳐먹어 쫌있음 개인스케줄 만남소원해져서 이별 할거뻔하고 저것들이 가수냐 댄서지 댄서들 끝은 99 프로 새드앤딩 그리고 철이없어도 너무없다 \n",
      "\n",
      "\n",
      "56\n",
      "원본 :  이던이 인기를 끌면 무조건 현아는 버려진다. \n",
      "max :  이던이 인기를 끌면 무조건 현아는 버려진다 . \n",
      "\n",
      "\n",
      "57\n",
      "원본 :  이런 걸 왜 찍는걸까? 성관계 동영상 찍는 거랑 같은 거 아닌가? \n",
      "max :  이런 걸 왜 찍는걸까 ? 성관계 동영상 찍는 거랑 같은 거 아닌가 ? \n",
      "\n",
      "\n",
      "58\n",
      "원본 :  멋있기만 하구만.이러다 헤어지면 헤어지는거지뭐.연예할때 맘껏 즐기는거 보기 좋은데.내숭보단 훨씬 낫다.화이팅!! \n",
      "max :  멋있기만 하구만 . 이러다 헤어지면 헤어지는거지뭐 . 연예할때 맘껏 즐기는거 보기 좋은데 . 내숭보단 훨씬 낫다 . 화이팅 !! \n",
      "\n",
      "\n",
      "60\n",
      "원본 :  ㅋㅋㅋ 생각이라는 걸 하고 산다면...ㅋㅋㅋㅋ \n",
      "max :  ㅋㅋㅋ 생각이라는 걸 하고 산다면 ... ㅋㅋㅋㅋ \n",
      "\n",
      "\n",
      "61\n",
      "원본 :  적당히좀 해라. \n",
      "max :  적당히좀 해라 . \n",
      "\n",
      "\n",
      "64\n",
      "원본 :  프로다운대처는 무슨..그러고 돌아다니면 애들이 따라한다 행실을 똑바로해라.. \n",
      "max :  프로다운대처는 무슨 .. 그러고 돌아다니면 애들이 따라한다 행실을 똑바로해라 .. \n",
      "\n",
      "\n",
      "65\n",
      "원본 :  화나요는 다 여자가누른듯, , ,,인정하면 up, , , \n",
      "max :  화나요는 다 여자가누른듯 , , ,, 인정하면 up , , , \n",
      "\n",
      "\n",
      "68\n",
      "원본 :  그걸 즐기는 거면 할 말은 없다만~ ㅋㅋㅋㅋ 같은 저러는 거 이해가 안 되긴 함 ㅋㅋㅋㅋㅋㅋ \n",
      "max :  그걸 즐기는 거면 할 말은 없다만 ~ ㅋㅋㅋㅋ 같은 저러는 거 이해가 안 되긴 함 ㅋㅋㅋㅋㅋㅋ \n",
      "\n",
      "\n",
      "71\n",
      "원본 :  한때나마 내가 예진이를 좋아했다는게 너무 창피하다 ㅠ 아줌마 예진이... 이건 아니거던... 아... 나 엄청 챙피 꽥하고파 ㅠ \n",
      "max :  한때나마 내가 예진이를 좋아했다는게 너무 창피하다 ㅠ 아줌마 예진이 ... 이건 아니거던 ... 아 ... 나 엄청 챙피 꽥하고파 ㅠ \n",
      "\n",
      "\n",
      "73\n",
      "원본 :  정우성도 드라마 하나 찍어라. 정우성표 로맨스 보고 싶다. 잘생긴 아저씨의 대표주자. 비트 때는 정말 인간이 아니었는데... 뭔가 잘생겼는데 우수에 찬 느낌도 있고....그냥 잘생기지 않았음 정우성은. \n",
      "max :  정우성도 드라마 하나 찍어라 . 정우성표 로맨스 보고 싶다 . 잘생긴 아저씨의 대표주자 . 비트 때는 정말 인간이 아니었는데 ... 뭔가 잘생겼는데 우수에 찬 느낌도 있고 .... 그냥 잘생기지 않았음 정우성은 . \n",
      "\n",
      "\n",
      "74\n",
      "원본 :  용두사미. 실망했어요. \n",
      "max :  용두사미 . 실망했어요 . \n",
      "\n",
      "\n",
      "77\n",
      "원본 :  쉰내나는 40대 아줌마들이 빠는 이드라마 이제 랭킹 뉴스에서 이제 안보게되서 너무기쁨 40대 아줌마 아저씨 로맨스라 1도 몰입안됨 ㅋㅋㅋ \n",
      "max :  쉰내나는 40 대 아줌마들이 빠는 이드라마 이제 랭킹 뉴스에서 이제 안보게되서 너무기쁨 40 대 아줌마 아저씨 로맨스라 1 도 몰입안됨 ㅋㅋㅋ \n",
      "\n",
      "\n",
      "82\n",
      "원본 :  사내자슥이 비실비실 할때부터 알아봤다!!! \n",
      "max :  사내자슥이 비실비실 할때부터 알아봤다 !!! \n",
      "\n",
      "\n",
      "83\n",
      "원본 :  당신을 믿습니다꼭 전보다 더 건강한 모습으로 만나요멋진 허지웅 화이팅! \n",
      "max :  당신을 믿습니다꼭 전보다 더 건강한 모습으로 만나요멋진 허지웅 화이팅 ! \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dif_idx2 = test[test['comments'] != test['reg']].index\n",
    "print(len(dif_idx2))\n",
    "for idx in dif_idx2[0:50]:\n",
    "    print(idx)\n",
    "    print('원본 : ', test['comments'][idx],'\\nmax : ', test['reg'][idx], '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리후 f1-score  단순 비교 \n",
    "- 1. soynlp 반복제거 repeat_normalize\n",
    "    - 1.1 soynlp 반복제거 - okt 형태소 --> 부질없음\n",
    "- 2. okt 형태소 적용\n",
    "    - 2.1 okt - soynlp 반복제거\n",
    "- 3. soynlp MaxScoreTokenizer\n",
    "    - 3.1 soynlp MaxScoreTokenizer - okt  \n",
    "- 4. 3다 합쳐서\n",
    "    - 3 - 1\n",
    "    - 3 - 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "dev = pd.read_csv('./korean-hate-speech-master/labeled/dev.tsv', sep='\\t')\n",
    "dev = dev[['comments', 'hate']]\n",
    "dev.columns = ['comments', 'label']\n",
    "dev = kaggle_format(dev)\n",
    "dev = dev.astype({'label': 'str'})\n",
    "X_test, y_test = dev.comments, dev.label\n",
    "\n",
    "def get_f1_score(pre_data):\n",
    "    vec = TfidfVectorizer(min_df=0.0, analyzer='char', ngram_range=(1,3), sublinear_tf=True,\n",
    "               max_features=100000)\n",
    "    X_tf = vec.fit_transform(pre_data)\n",
    "    print(X_tf.shape)\n",
    "    lgs = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=1, \n",
    "                         class_weight='balanced', \n",
    "                         max_iter=6000, random_state=10)\n",
    "    lgs.fit(X_tf, y)\n",
    "    X_test_tf = vec.transform(X_test)\n",
    "    pred =  lgs.predict(X_test_tf)\n",
    "    return f1_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, scores_h = [], [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "repeat_normalize :  0.6192400765926616\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "ls = []\n",
    "for c in X:\n",
    "    ls.append(repeat_normalize(c, num_repeats=2))\n",
    "\n",
    "score_soynlp = get_f1_score(ls)\n",
    "\n",
    "scores.append(score_soynlp)\n",
    "scores_h.append('repeat_normalize')\n",
    "\n",
    "print('baseline : ', baseline)\n",
    "print('repeat_normalize : ', score_soynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 99974)\n",
      "baseline :  0.6171504866913602\n",
      "okt :  <konlpy.tag._okt.Okt object at 0x00000204D33B3808>\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "ls = []\n",
    "for c in X:\n",
    "    ls.append(' '.join(okt.morphs(c)))\n",
    "score_okt = get_f1_score(ls)\n",
    "\n",
    "scores.append(score_okt)\n",
    "scores_h.append('okt')\n",
    "\n",
    "print('baseline : ', baseline)\n",
    "print('okt : ', okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 99969)\n",
      "baseline :  0.6171504866913602\n",
      "okt - soynlp :  0.5755498911931505\n"
     ]
    }
   ],
   "source": [
    "# 2-1\n",
    "ls = []\n",
    "for c in X:\n",
    "    c2 = ' '.join(okt.morphs(c))\n",
    "    ls.append(repeat_normalize(c2, num_repeats=2))\n",
    "\n",
    "score_okt_soynlp = get_f1_score(ls)\n",
    "\n",
    "scores.append(score_okt_soynlp)\n",
    "scores_h.append('okt--repeat_normalize')\n",
    "\n",
    "print('baseline : ', baseline)\n",
    "print('okt - soynlp : ', score_okt_soynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "soynlp MaxScoreTokenizer :  0.618094549129032\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "ls = []\n",
    "for c in X:\n",
    "    ls.append(' '.join(maxscore_tokenizer.tokenize(c)))\n",
    "score_tok = get_f1_score(ls)\n",
    "\n",
    "scores.append(score_tok)\n",
    "scores_h.append('maxscore_tokenizer')\n",
    "print('baseline : ', baseline)\n",
    "print('soynlp MaxScoreTokenizer : ', score_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "soynlp MaxScoreTokenizer - okt :  0.5802087234770893\n"
     ]
    }
   ],
   "source": [
    "# 3-1\n",
    "ls = []\n",
    "for c in X:\n",
    "    c2 = ' '.join(maxscore_tokenizer.tokenize(c))\n",
    "    ls.append(' '.join(okt.morphs(c2)))\n",
    "score_tok_okt = get_f1_score(ls)\n",
    "\n",
    "scores.append(score_tok_okt)\n",
    "scores_h.append('maxscore_tokenizer--okt')\n",
    "print('baseline : ', baseline)\n",
    "print('soynlp MaxScoreTokenizer - okt : ', score_tok_okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "soynlp MaxScoreTokenizer - 반복 제거 :  0.6254578916861416\n"
     ]
    }
   ],
   "source": [
    "# 4 : 3 - 1\n",
    "ls = []\n",
    "for c in X:\n",
    "    c2 = repeat_normalize(c, num_repeats=2)\n",
    "    ls.append(' '.join(maxscore_tokenizer.tokenize(c2)))\n",
    "score_tok_soynlp = get_f1_score(ls)\n",
    "\n",
    "scores.append(score_tok_soynlp)\n",
    "scores_h.append('repeat_normalize--maxscore_tokenizer')\n",
    "print('baseline : ', baseline)\n",
    "print('soynlp MaxScoreTokenizer - 반복 제거 : ', score_tok_soynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "soynlp MaxScoreTokenizer - okt - 반복 제거 :  0.5802087234770893\n"
     ]
    }
   ],
   "source": [
    "# 4-1 : 3 - 2 - 1\n",
    "ls = []\n",
    "for c in X:\n",
    "    c2 = ' '.join(maxscore_tokenizer.tokenize(c))\n",
    "    c3 = ' '.join(okt.morphs(c2))\n",
    "    ls.append(repeat_normalize(c3, num_repeats=2))\n",
    "score_tok_okt_soynlp = get_f1_score(ls)\n",
    "\n",
    "scores.append(score_tok_okt_soynlp)\n",
    "scores_h.append('maxscore_tokenizer--okt--repeat_normalize')\n",
    "print('baseline : ', baseline)\n",
    "print('soynlp MaxScoreTokenizer - okt - 반복 제거 : ', score_tok_okt_soynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "score MaxScoreTokenizer :  0.6006629623112639\n"
     ]
    }
   ],
   "source": [
    "# 5 : 특별 케이스\n",
    "ls = []\n",
    "for c in X:\n",
    "    c = repeat_normalize(c, num_repeats=2)\n",
    "    ls.append(' '.join(maxscore_tokenizer.tokenize(c)))\n",
    "score_tok_okt_soynlp = get_f1_score(ls)\n",
    "\n",
    "scores.append(score_tok_okt_soynlp)\n",
    "scores_h.append('score--maxscore_tokenizer')\n",
    "print('baseline : ', baseline)\n",
    "print('score MaxScoreTokenizer : ', score_tok_okt_soynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "score MaxScoreTokenizer :  0.5977665925361016\n"
     ]
    }
   ],
   "source": [
    "# 5 : 특별 케이스\n",
    "ls = []\n",
    "for c in X:\n",
    "    ls.append(' '.join(tokenizer.tokenize(c)))\n",
    "score_tok = get_f1_score(ls)\n",
    "\n",
    "scores.append(score_tok_okt_soynlp)\n",
    "scores_h.append('score--maxscore_tokenizer')\n",
    "print('baseline : ', baseline)\n",
    "print('score MaxScoreTokenizer : ', score_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619240</td>\n",
       "      <td>repeat_normalize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.573148</td>\n",
       "      <td>okt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.575550</td>\n",
       "      <td>okt--repeat_normalize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.618095</td>\n",
       "      <td>maxscore_tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.580209</td>\n",
       "      <td>maxscore_tokenizer--okt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.625458</td>\n",
       "      <td>repeat_normalize--maxscore_tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.580209</td>\n",
       "      <td>maxscore_tokenizer--okt--repeat_normalize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                       test\n",
       "0  0.619240                           repeat_normalize\n",
       "1  0.573148                                        okt\n",
       "2  0.575550                      okt--repeat_normalize\n",
       "3  0.618095                         maxscore_tokenizer\n",
       "4  0.580209                    maxscore_tokenizer--okt\n",
       "5  0.625458       repeat_normalize--maxscore_tokenizer\n",
       "6  0.580209  maxscore_tokenizer--okt--repeat_normalize"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 : score_tok_soynlp 0.625458(dev/ f1) 0.53271(kaggle)\n",
    "df = pd.DataFrame({'score': scores, 'test': scores_h})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.625458</td>\n",
       "      <td>repeat_normalize--maxscore_tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619240</td>\n",
       "      <td>repeat_normalize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.618095</td>\n",
       "      <td>maxscore_tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.580209</td>\n",
       "      <td>maxscore_tokenizer--okt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.580209</td>\n",
       "      <td>maxscore_tokenizer--okt--repeat_normalize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.575550</td>\n",
       "      <td>okt--repeat_normalize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.573148</td>\n",
       "      <td>okt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                       test\n",
       "5  0.625458       repeat_normalize--maxscore_tokenizer\n",
       "0  0.619240                           repeat_normalize\n",
       "3  0.618095                         maxscore_tokenizer\n",
       "4  0.580209                    maxscore_tokenizer--okt\n",
       "6  0.580209  maxscore_tokenizer--okt--repeat_normalize\n",
       "2  0.575550                      okt--repeat_normalize\n",
       "1  0.573148                                        okt"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1-score가 높았던 2개를 올려봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(df, X_train):\n",
    "    vec = TfidfVectorizer(min_df=0.0, analyzer='char', ngram_range=(1,3), sublinear_tf=True,\n",
    "               max_features=100000)\n",
    "    X_tf = vec.fit_transform(X_train)\n",
    "    print(X_tf.shape)\n",
    "    lgs = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=0.9, \n",
    "                         class_weight='balanced', \n",
    "                         max_iter=6000, random_state=10).fit(X_tf, y)\n",
    "    X_test_tf = vec.transform(df['comments'])\n",
    "    df['label'] = lgs.predict(X_test_tf)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for c in X:\n",
    "    c2 = repeat_normalize(c, num_repeats=2)\n",
    "    ls.append(' '.join(maxscore_tokenizer.tokenize(c2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./korean-hate-speech-master/test.no_label.tsv', sep='\\t')\n",
    "test_df = get_test(test, ls)\n",
    "test_df.to_csv('score_tok_soynlp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그러면 똑같은 방식이지만 음...\n",
    "- 문자 길이가 짧은것은 날리도록\n",
    "- kss 적용해 볼것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7893"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lens = [len(c) for c in X]\n",
    "len(X_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.70923603192703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1870., 2060., 1334.,  924.,  583.,  380.,  318.,  210.,  162.,\n",
       "          52.]),\n",
       " array([  4. ,  17.1,  30.2,  43.3,  56.4,  69.5,  82.6,  95.7, 108.8,\n",
       "        121.9, 135. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 387
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(np.mean(X_lens))\n",
    "plt.hist(X_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자 10개 미만 날렸을 때 --> 0.6030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(pre_data, y):\n",
    "    vec = TfidfVectorizer(min_df=0.0, analyzer='char', ngram_range=(1,3), sublinear_tf=True,\n",
    "               max_features=100000)\n",
    "    X_tf = vec.fit_transform(pre_data)\n",
    "    print(X_tf.shape)\n",
    "    lgs = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=1, \n",
    "                         class_weight='balanced', \n",
    "                         max_iter=6000, random_state=10)\n",
    "    lgs.fit(X_tf, y)\n",
    "    X_test_tf = vec.transform(X_test)\n",
    "    pred =  lgs.predict(X_test_tf)\n",
    "    return f1_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10자 미만 날리고\n",
    "idx_ls = []\n",
    "for idx in range(len(X)):\n",
    "    if len(train['comments'][idx]) > 10:\n",
    "        idx_ls.append(idx)\n",
    "        \n",
    "train_10 = train.iloc[idx_ls]\n",
    "X_10, y_10 = train_10.comments, train_10.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7264, 100000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6013859361596164"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_f1_score(X_10, y_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7264, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "soynlp MaxScoreTokenizer - 반복 제거 :  0.6030696351851449\n"
     ]
    }
   ],
   "source": [
    "# 추가 전처리 이후 결과\n",
    "ls = []\n",
    "for c in X_10:\n",
    "    c2 = repeat_normalize(c, num_repeats=2)\n",
    "    ls.append(' '.join(maxscore_tokenizer.tokenize(c2)))\n",
    "score_tok_soynlp_10 = get_f1_score(ls, y_10)\n",
    "\n",
    "scores.append(score_tok_soynlp_10)\n",
    "scores_h.append('score_tok_soynlp_10')\n",
    "print('baseline : ', baseline)\n",
    "print('soynlp MaxScoreTokenizer - 반복 제거 : ', score_tok_soynlp_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7567\n",
      "(7567, 100000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6140271731407919"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8자 미만 날리고\n",
    "idx_ls = []\n",
    "for idx in range(len(X)):\n",
    "    if len(train['comments'][idx]) > 8:\n",
    "        idx_ls.append(idx)\n",
    "        \n",
    "train_8 = train.iloc[idx_ls]\n",
    "X_8, y_8 = train_8.comments, train_8.label\n",
    "print(len(X_8))\n",
    "get_f1_score(X_8, y_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7567, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "soynlp MaxScoreTokenizer - 반복 제거 :  0.6124161341069015\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for c in X_8:\n",
    "    c2 = repeat_normalize(c, num_repeats=2)\n",
    "    ls.append(' '.join(maxscore_tokenizer.tokenize(c2)))\n",
    "score_tok_soynlp_8 = get_f1_score(ls, y_8)\n",
    "\n",
    "scores.append(score_tok_soynlp_8)\n",
    "scores_h.append('score_tok_soynlp_8')\n",
    "print('baseline : ', baseline)\n",
    "print('soynlp MaxScoreTokenizer - 반복 제거 : ', score_tok_soynlp_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7860\n",
      "(7860, 100000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6145343114010919"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5자 미만 날리고\n",
    "idx_ls = []\n",
    "for idx in range(len(X)):\n",
    "    if len(train['comments'][idx]) > 5:\n",
    "        idx_ls.append(idx)\n",
    "        \n",
    "train_5 = train.iloc[idx_ls]\n",
    "X_5, y_5 = train_5.comments, train_5.label\n",
    "print(len(X_5))\n",
    "get_f1_score(X_5, y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7860, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "soynlp MaxScoreTokenizer - 반복 제거 :  0.6182984374314718\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for c in X_5:\n",
    "    c2 = repeat_normalize(c, num_repeats=2)\n",
    "    ls.append(' '.join(maxscore_tokenizer.tokenize(c2)))\n",
    "score_tok_soynlp_5 = get_f1_score(ls, y_5)\n",
    "\n",
    "scores.append(score_tok_soynlp_5)\n",
    "scores_h.append('score_tok_soynlp_5')\n",
    "print('baseline : ', baseline)\n",
    "print('soynlp MaxScoreTokenizer - 반복 제거 : ', score_tok_soynlp_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6407\n",
      "(6407, 100000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.599005029125511"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5자 미만 날리고\n",
    "idx_ls = []\n",
    "for idx in range(len(X)):\n",
    "    if len(train['comments'][idx]) > 15:\n",
    "        idx_ls.append(idx)\n",
    "        \n",
    "train_15 = train.iloc[idx_ls]\n",
    "X_15, y_15 = train_15.comments, train_15.label\n",
    "print(len(X_15))\n",
    "get_f1_score(X_15, y_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 띄워쓰기 kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss\n",
    "\n",
    "test = pd.DataFrame()\n",
    "ls = []\n",
    "for c in X:\n",
    "    ls.append(' '.join(kss.split_sentences(c)))\n",
    "test['comments'] = X\n",
    "test['kss'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>kss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>에이미 제발 조용히 사세요..다른 사람에게 피해주지마라..너로 인하여 아무 이유없이...</td>\n",
       "      <td>에이미 제발 조용히 사세요.. 다른 사람에게 피해주지마라.. 너로 인하여 아무 이유...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>기자앙반아 명품이란말 올려놓구 착한 이진이 뭔잘못이 있다고욕을먹게하냐? 실수했다기레기야</td>\n",
       "      <td>기자앙반아 명품이란말 올려놓구 착한 이진이 뭔잘못이 있다고욕을먹게하냐? 실수했다 기레기야</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>그냥 전라도사람들이 예민한듯 저발언을 부산에서 했다생각해봐 그냥 웃어 넘겼음</td>\n",
       "      <td>그냥 전라도사람들이 예민한듯 저발언을 부산에서 했다 생각해봐 그냥 웃어 넘겼음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>너무 싸보이는 느낌..살려고 발버둥치는것 같긴한데...좀 안타깝군요싸이는 어쩔려고...</td>\n",
       "      <td>너무 싸보이는 느낌..살려고 발버둥치는것 같긴한데...좀 안타깝군요 싸이는 어쩔려고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>태국 가서 머했을까...궁금궁금</td>\n",
       "      <td>태국 가서 머했을까... 궁금궁금</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7855</th>\n",
       "      <td>정신적으로이상자들 왜이렇게까지 살을빼는거지?문제다</td>\n",
       "      <td>정신적으로이상자들 왜이렇게까지 살을빼는거지? 문제다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7861</th>\n",
       "      <td>건강하게 다이어트하셔서 더보기좋은듯합니당ㅋ넘이쁘심!! 복면가왕한번더출연하세요~~아무...</td>\n",
       "      <td>건강하게 다이어트하셔서 더보기좋은듯합니당ㅋ넘이쁘심!! 복면가왕한번더출연하세요~~ 아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>왜 연예인이 다이어트 성공한거나 임 신한걸 뉴스 기사로 봐야하는거지 대단한건가?몇달...</td>\n",
       "      <td>왜 연예인이 다이어트 성공한거나 임 신한걸 뉴스 기사로 봐야하는거지 대단한건가? 몇...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>음주운전 또 면죄부? 미친 방송국 놈들. 호란이야 아쉬웠겠지만 시청자는 아쉽지 않은...</td>\n",
       "      <td>음주운전 또 면죄부? 미친 방송국 놈들. 호란이야 아쉬웠겠지만 시청자는 아쉽지 않은...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>그러지마셔요 범죄자(살인미수) 음주운전은 살인미수예요.반성따위 없어요 이런 글 보면...</td>\n",
       "      <td>그러지마셔요 범죄자(살인미수) 음주운전은 살인미수예요. 반성따위 없어요 이런 글 보...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comments  \\\n",
       "6     에이미 제발 조용히 사세요..다른 사람에게 피해주지마라..너로 인하여 아무 이유없이...   \n",
       "21     기자앙반아 명품이란말 올려놓구 착한 이진이 뭔잘못이 있다고욕을먹게하냐? 실수했다기레기야   \n",
       "43           그냥 전라도사람들이 예민한듯 저발언을 부산에서 했다생각해봐 그냥 웃어 넘겼음   \n",
       "49     너무 싸보이는 느낌..살려고 발버둥치는것 같긴한데...좀 안타깝군요싸이는 어쩔려고...   \n",
       "51                                    태국 가서 머했을까...궁금궁금   \n",
       "...                                                 ...   \n",
       "7855                        정신적으로이상자들 왜이렇게까지 살을빼는거지?문제다   \n",
       "7861  건강하게 다이어트하셔서 더보기좋은듯합니당ㅋ넘이쁘심!! 복면가왕한번더출연하세요~~아무...   \n",
       "7864  왜 연예인이 다이어트 성공한거나 임 신한걸 뉴스 기사로 봐야하는거지 대단한건가?몇달...   \n",
       "7869  음주운전 또 면죄부? 미친 방송국 놈들. 호란이야 아쉬웠겠지만 시청자는 아쉽지 않은...   \n",
       "7871  그러지마셔요 범죄자(살인미수) 음주운전은 살인미수예요.반성따위 없어요 이런 글 보면...   \n",
       "\n",
       "                                                    kss  \n",
       "6     에이미 제발 조용히 사세요.. 다른 사람에게 피해주지마라.. 너로 인하여 아무 이유...  \n",
       "21    기자앙반아 명품이란말 올려놓구 착한 이진이 뭔잘못이 있다고욕을먹게하냐? 실수했다 기레기야  \n",
       "43          그냥 전라도사람들이 예민한듯 저발언을 부산에서 했다 생각해봐 그냥 웃어 넘겼음  \n",
       "49    너무 싸보이는 느낌..살려고 발버둥치는것 같긴한데...좀 안타깝군요 싸이는 어쩔려고...  \n",
       "51                                   태국 가서 머했을까... 궁금궁금  \n",
       "...                                                 ...  \n",
       "7855                       정신적으로이상자들 왜이렇게까지 살을빼는거지? 문제다  \n",
       "7861  건강하게 다이어트하셔서 더보기좋은듯합니당ㅋ넘이쁘심!! 복면가왕한번더출연하세요~~ 아...  \n",
       "7864  왜 연예인이 다이어트 성공한거나 임 신한걸 뉴스 기사로 봐야하는거지 대단한건가? 몇...  \n",
       "7869  음주운전 또 면죄부? 미친 방송국 놈들. 호란이야 아쉬웠겠지만 시청자는 아쉽지 않은...  \n",
       "7871  그러지마셔요 범죄자(살인미수) 음주운전은 살인미수예요. 반성따위 없어요 이런 글 보...  \n",
       "\n",
       "[907 rows x 2 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.comments != test.kss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6247941204142539"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_f1_score(test['kss'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./korean-hate-speech-master/test.no_label.tsv', sep='\\t')\n",
    "test_df = get_test(test, ls)\n",
    "test_df.to_csv('score_tok_soynlp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "soynlp MaxScoreTokenizer - 반복 제거 :  0.6182984374314718\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for c in test['kss']:\n",
    "    c2 = repeat_normalize(c, num_repeats=2)\n",
    "    ls.append(' '.join(maxscore_tokenizer.tokenize(c2)))\n",
    "score__kss_tok_soynlp = get_f1_score(ls, y)\n",
    "\n",
    "scores.append(score__kss_tok_soynlp)\n",
    "scores_h.append('score__kss_tok_soynlp')\n",
    "print('baseline : ', baseline)\n",
    "print('soynlp MaxScoreTokenizer - 반복 제거 : ', score__kss_tok_soynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7893, 100000)\n",
      "baseline :  0.6171504866913602\n",
      "soynlp MaxScoreTokenizer - 반복 제거 :  0.6230257738183211\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for c in X:\n",
    "    c2 = repeat_normalize(c, num_repeats=2)\n",
    "    c3 = ' '.join(maxscore_tokenizer.tokenize(c2))\n",
    "    ls.append(' '.join(kss.split_sentences(c3)))\n",
    "score__kss_tok_soynlp = get_f1_score(ls, y)\n",
    "\n",
    "scores.append(score__kss_tok_soynlp)\n",
    "scores_h.append('score__kss_tok_soynlp')\n",
    "print('baseline : ', baseline)\n",
    "print('soynlp MaxScoreTokenizer - 반복 제거 : ', score__kss_tok_soynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ca83bd5bbc2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m vec = TfidfVectorizer(min_df=0.0, analyzer='char', ngram_range=(1,3), \n\u001b[0;32m      6\u001b[0m                       sublinear_tf=True, max_features=10000)\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_tf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "vec = TfidfVectorizer(min_df=0.0, analyzer='char', ngram_range=(1,3), \n",
    "                      sublinear_tf=True, max_features=10000)\n",
    "X_tf = vec.fit_transform(X)\n",
    "print(X_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lgs = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=1, \n",
    "                     class_weight='balanced', \n",
    "                     max_iter=6000, random_state=10)\n",
    "lgs.fit(X_tf, y)\n",
    "X_test_tf = vec.transform(X_test)\n",
    "pred =  lgs.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5910663394900268"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
