{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt; t = Okt()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               comments bias_label  \\\n",
       "7891                                         힘내세요,응원합니다       none   \n",
       "7892                                힘내세요,삼가 고인의 명복을 빕니다       none   \n",
       "7893                                      힘내세용 항상 응원합니닷       none   \n",
       "7894  힘내 소연기로 답해요,나도 53살 인데 이런 일 저런 일 다 있더라구 요인격을 믿습...       none   \n",
       "7895                                힘들면 관뒀어야지 그게 현명한 거다       none   \n",
       "\n",
       "      gender_label hate_label                                     news_title  \\\n",
       "7891         False       none                허지웅 허투루 넘길 말 없었다,솔직하게 드러냈던 속 사정   \n",
       "7892         False       none            이혜경 오 캐롤 공연 중 남편 오정욱 부 고 오열 속 발인 종합   \n",
       "7893         False       none                     설경구 송윤아 아들과 즐거운 하루 전 엄마니까요   \n",
       "7894         False       none  SC 현장 연예인 인생 협박 유감 미소 잃은 최민수 보복운전 혐의 2차 공판 종합   \n",
       "7895         False       none                단독 스태프 사망 사고 서른 이지만 결국 오늘 촬영 취소   \n",
       "\n",
       "                                            comment_pos  \\\n",
       "7891  [('힘내세요', 'Verb'), (',', 'Punctuation'), ('응원'...   \n",
       "7892  [('힘내세요', 'Verb'), (',', 'Punctuation'), ('삼가'...   \n",
       "7893  [('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...   \n",
       "7894  [('힘내', 'Verb'), ('소', 'Modifier'), ('연기', 'No...   \n",
       "7895  [('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...   \n",
       "\n",
       "                                              title_pos  \n",
       "7891  [('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...  \n",
       "7892  [('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...  \n",
       "7893  [('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...  \n",
       "7894  [('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...  \n",
       "7895  [('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>bias_label</th>\n      <th>gender_label</th>\n      <th>hate_label</th>\n      <th>news_title</th>\n      <th>comment_pos</th>\n      <th>title_pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7891</th>\n      <td>힘내세요,응원합니다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>허지웅 허투루 넘길 말 없었다,솔직하게 드러냈던 속 사정</td>\n      <td>[('힘내세요', 'Verb'), (',', 'Punctuation'), ('응원'...</td>\n      <td>[('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...</td>\n    </tr>\n    <tr>\n      <th>7892</th>\n      <td>힘내세요,삼가 고인의 명복을 빕니다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>이혜경 오 캐롤 공연 중 남편 오정욱 부 고 오열 속 발인 종합</td>\n      <td>[('힘내세요', 'Verb'), (',', 'Punctuation'), ('삼가'...</td>\n      <td>[('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...</td>\n    </tr>\n    <tr>\n      <th>7893</th>\n      <td>힘내세용 항상 응원합니닷</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>설경구 송윤아 아들과 즐거운 하루 전 엄마니까요</td>\n      <td>[('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...</td>\n      <td>[('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...</td>\n    </tr>\n    <tr>\n      <th>7894</th>\n      <td>힘내 소연기로 답해요,나도 53살 인데 이런 일 저런 일 다 있더라구 요인격을 믿습...</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>SC 현장 연예인 인생 협박 유감 미소 잃은 최민수 보복운전 혐의 2차 공판 종합</td>\n      <td>[('힘내', 'Verb'), ('소', 'Modifier'), ('연기', 'No...</td>\n      <td>[('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...</td>\n    </tr>\n    <tr>\n      <th>7895</th>\n      <td>힘들면 관뒀어야지 그게 현명한 거다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>단독 스태프 사망 사고 서른 이지만 결국 오늘 촬영 취소</td>\n      <td>[('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...</td>\n      <td>[('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "train = pd.read_csv('./datas/train_ver1', index_col=[0])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              comments hate_label\n",
       "466                                  지현우 범죄 저지르지 않았나요?  offensive\n",
       "467                                    여자인생 망칠 일 있나 ㅋㅋ       hate\n",
       "468            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?  offensive\n",
       "469  할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...       hate\n",
       "470  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...       none"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>hate_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>466</th>\n      <td>지현우 범죄 저지르지 않았나요?</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>여자인생 망칠 일 있나 ㅋㅋ</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>470</th>\n      <td>남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...</td>\n      <td>none</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dev = pd.read_csv('./datas/dev.hate.csv')\n",
    "dev.rename(columns={'label': 'hate_label'}, inplace=True)\n",
    "dev.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_tokenizer(text):\n",
    "    tokens_ko = t.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(tokenizer=t_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf_vect.fit(train['comments'])\n",
    "tfidf_matrix_train = tfidf_vect.transform(train['comments'])"
   ]
  },
  {
   "source": [
    "## LGBMClassifier compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 7.578863859176636\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "lgbm_clf = LGBMClassifier(n_estimators=400)\n",
    "lgbm_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5414012738853503, 0.5360114752270562)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "\n",
    "tfidf_matrix_dev = tfidf_vect.transform(dev['comments'])\n",
    "preds = lgbm_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "source": [
    "## DecisionTreeClassifier compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 8.65710735321045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_clf = DecisionTreeClassifier(max_depth=2, random_state=13)\n",
    "decision_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.4118895966029724, 0.33302547396349347)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "preds = decision_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "source": [
    "## LogisticRegression compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 8.741127967834473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', random_state=13)\n",
    "lr.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5944798301486199, 0.5861227653087044)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "preds = lr.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "source": [
    "## GradientBoostingClassifier compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 944.8058462142944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=13)\n",
    "gb_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5095541401273885, 0.48810533169257236)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "preds = gb_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting xgboost\n  Downloading xgboost-1.3.1-py3-none-win_amd64.whl (95.2 MB)\nRequirement already satisfied: numpy in c:\\users\\luvu1\\anaconda3\\envs\\nltk\\lib\\site-packages (from xgboost) (1.19.4)\nRequirement already satisfied: scipy in c:\\users\\luvu1\\anaconda3\\envs\\nltk\\lib\\site-packages (from xgboost) (1.5.4)\nInstalling collected packages: xgboost\nSuccessfully installed xgboost-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "source": [
    "## XGBClassifier compare train and dev data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[00:20:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit time: 153.06296706199646\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "xgb_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5222929936305732, 0.5038136262817716)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "preds = xgb_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, class_train, class_test = train_test_split(tfidf_matrix_train, train['hate_label'], test_size=0.2, stratify=train['hate_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = []\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "models.append(('LogisticRegression', LogisticRegression()))\n",
    "models.append(('LGBMClassifier', LGBMClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Acc :  0.9988917036098797\n",
      "Test Acc :  0.5360759493670886\n",
      "Train Acc :  0.9988917036098797\n",
      "Test Acc :  0.46392405063291137\n",
      "Train Acc :  0.5582647245091831\n",
      "Test Acc :  0.510759493670886\n",
      "Train Acc :  0.652786573780874\n",
      "Test Acc :  0.5259493670886076\n",
      "Train Acc :  0.8530715642811906\n",
      "Test Acc :  0.5430379746835443\n",
      "Train Acc :  0.8096896770107663\n",
      "Test Acc :  0.5316455696202531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(msg_train, class_train)\n",
    "    \n",
    "    y_pred_tr = clf.predict(msg_train)\n",
    "    y_pred_test = clf.predict(msg_test)\n",
    "    \n",
    "    print('Train Acc : ', accuracy_score(class_train, y_pred_tr))\n",
    "    print('Test Acc : ', accuracy_score(class_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "names = []\n",
    "f1score = []\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(msg_train, class_train)\n",
    "    \n",
    "    y_pred_tr = clf.predict(msg_train)\n",
    "    y_pred_test = clf.predict(msg_test)\n",
    "    \n",
    "    names.append(name)\n",
    "    test_score.append(accuracy_score(class_test, y_pred_test))\n",
    "    train_score.append(accuracy_score(class_train, y_pred_tr))\n",
    "    f1score.append(f1_score(class_test, y_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   model name  train score  test score  f1 score\n",
       "0      RandomForestClassifier     0.998892    0.532911  0.474092\n",
       "1      DecisionTreeClassifier     0.998892    0.473418  0.441096\n",
       "2          AdaBoostClassifier     0.558265    0.510759  0.444480\n",
       "3  GradientBoostingClassifier     0.652787    0.524684  0.451602\n",
       "4          LogisticRegression     0.853072    0.543038  0.507301\n",
       "5              LGBMClassifier     0.809690    0.531646  0.498601"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model name</th>\n      <th>train score</th>\n      <th>test score</th>\n      <th>f1 score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RandomForestClassifier</td>\n      <td>0.998892</td>\n      <td>0.532911</td>\n      <td>0.474092</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DecisionTreeClassifier</td>\n      <td>0.998892</td>\n      <td>0.473418</td>\n      <td>0.441096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AdaBoostClassifier</td>\n      <td>0.558265</td>\n      <td>0.510759</td>\n      <td>0.444480</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GradientBoostingClassifier</td>\n      <td>0.652787</td>\n      <td>0.524684</td>\n      <td>0.451602</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LogisticRegression</td>\n      <td>0.853072</td>\n      <td>0.543038</td>\n      <td>0.507301</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LGBMClassifier</td>\n      <td>0.809690</td>\n      <td>0.531646</td>\n      <td>0.498601</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "result = pd.DataFrame({'model name':names, \n",
    "                       'train score':train_score, \n",
    "                       'test score':test_score,\n",
    "                       'f1 score': f1score}) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}