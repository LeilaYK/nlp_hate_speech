{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt; t = Okt()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datas/train_ver1', index_col=[0])\n",
    "dev = pd.read_csv('./datas/dev.hate.csv')\n",
    "dev.rename(columns={'label': 'hate_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_tokenizer(text):\n",
    "    tokens_ko = t.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(tokenizer=t_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf_vect.fit(train['comments'])\n",
    "tfidf_matrix_train = tfidf_vect.transform(train['comments'])\n",
    "tfidf_matrix_dev = tfidf_vect.transform(dev['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 0.701613187789917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression()\n",
    "lr.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5923566878980892, 0.5862217149718904)"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "\n",
    "preds = lr.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "source": [
    "## using GridSearchCV with LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'C': [1, 3.5, 4.5, 5.5, 10]}\n",
    "gcv_lr = GridSearchCV(lr, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "gcv_lr.fit(tfidf_matrix_train, train['hate_label'])\n",
    "gcv_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5923566878980892, 0.5862217149718904)"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "best_estimator = gcv_lr.best_estimator_\n",
    "preds = best_estimator.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "source": [
    "## KMeans Clustering to LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               comments bias_label  \\\n",
       "0     현재 호텔 주인 심정 아18 난 마른 하늘에 날 벼락 맞고 호텔 망하게 생겼는데 누...     others   \n",
       "4568     엄하게 꾸짖는 것 보다,따뜻한 말 한마디가 나를 타인을 세상을 바꾸는 진리 감동ㅜㅜ       none   \n",
       "4566    엄연히 따지면 승리는 돈 벌자 고 범죄를 묵인 한 거고 얘는 지가 재미로 저지른 거지       none   \n",
       "4565                                         엄벌에 처해 주세요       none   \n",
       "4564                                        엄마한테 잘해야 해요       none   \n",
       "...                                                 ...        ...   \n",
       "6004  이젠 뭐라 해도 진심이 1도 읍 다 달게 받기는 확인 안 하면 질책도 안 보고 못 ...       none   \n",
       "7034  집사부 일체에 사부로 애들 잠깐 양념으로 나오는 건 그렇다 쳐도 이 영애 양심이 있...       none   \n",
       "549         계집들 댓글 보소 누가 아깝니 그런 개소리는 여자들 왜 하는 겨 여자 종특인가     gender   \n",
       "6001  이제는 이렇게 퍼 오는 거 신고해서 걸러내야 한다,그냥 기자들에게 저들의 일상은 돈...       none   \n",
       "5973                           이제 군대 피해의식에서 좀 벗어들 나 시지요     others   \n",
       "\n",
       "      gender_label hate_label  \\\n",
       "0            False       hate   \n",
       "4568         False       none   \n",
       "4566         False       none   \n",
       "4565         False       none   \n",
       "4564         False       none   \n",
       "...            ...        ...   \n",
       "6004         False  offensive   \n",
       "7034         False  offensive   \n",
       "549           True       hate   \n",
       "6001         False  offensive   \n",
       "5973         False  offensive   \n",
       "\n",
       "                                             news_title  \\\n",
       "0                    밤새 조문 행렬 전 미선 동료들이 그리워하는 따뜻한 배우 종합   \n",
       "4568  TV는 사랑을 싣고 김범룡 45억 빚 청산 후 찾은 첫사랑 국사 선생님과 재회 어저...   \n",
       "4566            공식 입장 정준영과 친분 No 모델 허현 측 몰카 논란 법적 대응 전문   \n",
       "4565             무면허 음주 뺑소니 손승원 보석 신청 술에 의 지하는 삶 살지 않겠다   \n",
       "4564             장윤정 도 경완 폭풍성장 아들과 캠핑 근황언젠간 엄마도 함께 SHOT   \n",
       "...                                                 ...   \n",
       "6004                  이종현 BJ 박민정 DM 논란 죄송 씨엔블루 탈퇴 결정 전문   \n",
       "7034                    집사부 일체 이영애 이상윤에 자녀 교육 상담 수학 어려워   \n",
       "549                         단독 장현승 신수지 4개월째 열애 볼링이 공통분모   \n",
       "6001                 차세찌 한 채 아 달콤한 키즈카페 데이트 커플 운동화 SHOT   \n",
       "5973                      단독 유승준 새 앨범 사죄와 반성 담아 용 서해주시길   \n",
       "\n",
       "                                            comment_pos  \\\n",
       "0     [('현재', 'Noun'), ('호텔', 'Noun'), ('주인', 'Noun'...   \n",
       "4568  [('엄하', 'Noun'), ('게', 'Josa'), ('꾸짖는', 'Verb'...   \n",
       "4566  [('엄연히', 'Adjective'), ('따지면', 'Verb'), ('승리',...   \n",
       "4565  [('엄벌', 'Noun'), ('에', 'Josa'), ('처', 'Noun'),...   \n",
       "4564  [('엄마', 'Noun'), ('한테', 'Josa'), ('잘해야', 'Noun...   \n",
       "...                                                 ...   \n",
       "6004  [('이', 'Determiner'), ('젠', 'Noun'), ('뭐라', 'V...   \n",
       "7034  [('집사부', 'Noun'), ('일체', 'Noun'), ('에', 'Josa'...   \n",
       "549   [('계집', 'Noun'), ('들', 'Suffix'), ('댓글', 'Noun...   \n",
       "6001  [('이제', 'Noun'), ('는', 'Josa'), ('이렇게', 'Adver...   \n",
       "5973  [('이제', 'Noun'), ('군대', 'Noun'), ('피해', 'Noun'...   \n",
       "\n",
       "                                              title_pos  cluster_label  \n",
       "0     [('밤새', 'Noun'), ('조문', 'Noun'), ('행렬', 'Noun'...              0  \n",
       "4568  [('TV', 'Alpha'), ('는', 'Verb'), ('사랑', 'Noun'...              0  \n",
       "4566  [('공식', 'Noun'), ('입장', 'Noun'), ('정준영', 'Noun...              0  \n",
       "4565  [('무면허', 'Noun'), ('음주', 'Noun'), ('뺑소니', 'Nou...              0  \n",
       "4564  [('장윤정', 'Noun'), ('도', 'Noun'), ('경완', 'Noun'...              0  \n",
       "...                                                 ...            ...  \n",
       "6004  [('이종현', 'Noun'), ('BJ', 'Alpha'), ('박민정', 'No...              2  \n",
       "7034  [('집사부', 'Noun'), ('일체', 'Noun'), ('이영애', 'Nou...              2  \n",
       "549   [('단독', 'Noun'), ('장현승', 'Noun'), ('신수지', 'Nou...              2  \n",
       "6001  [('차세', 'Verb'), ('찌', 'Noun'), ('한', 'Verb'),...              2  \n",
       "5973  [('단독', 'Noun'), ('유승준', 'Noun'), ('새', 'Noun'...              2  \n",
       "\n",
       "[7896 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>bias_label</th>\n      <th>gender_label</th>\n      <th>hate_label</th>\n      <th>news_title</th>\n      <th>comment_pos</th>\n      <th>title_pos</th>\n      <th>cluster_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>현재 호텔 주인 심정 아18 난 마른 하늘에 날 벼락 맞고 호텔 망하게 생겼는데 누...</td>\n      <td>others</td>\n      <td>False</td>\n      <td>hate</td>\n      <td>밤새 조문 행렬 전 미선 동료들이 그리워하는 따뜻한 배우 종합</td>\n      <td>[('현재', 'Noun'), ('호텔', 'Noun'), ('주인', 'Noun'...</td>\n      <td>[('밤새', 'Noun'), ('조문', 'Noun'), ('행렬', 'Noun'...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4568</th>\n      <td>엄하게 꾸짖는 것 보다,따뜻한 말 한마디가 나를 타인을 세상을 바꾸는 진리 감동ㅜㅜ</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>TV는 사랑을 싣고 김범룡 45억 빚 청산 후 찾은 첫사랑 국사 선생님과 재회 어저...</td>\n      <td>[('엄하', 'Noun'), ('게', 'Josa'), ('꾸짖는', 'Verb'...</td>\n      <td>[('TV', 'Alpha'), ('는', 'Verb'), ('사랑', 'Noun'...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4566</th>\n      <td>엄연히 따지면 승리는 돈 벌자 고 범죄를 묵인 한 거고 얘는 지가 재미로 저지른 거지</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>공식 입장 정준영과 친분 No 모델 허현 측 몰카 논란 법적 대응 전문</td>\n      <td>[('엄연히', 'Adjective'), ('따지면', 'Verb'), ('승리',...</td>\n      <td>[('공식', 'Noun'), ('입장', 'Noun'), ('정준영', 'Noun...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4565</th>\n      <td>엄벌에 처해 주세요</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>무면허 음주 뺑소니 손승원 보석 신청 술에 의 지하는 삶 살지 않겠다</td>\n      <td>[('엄벌', 'Noun'), ('에', 'Josa'), ('처', 'Noun'),...</td>\n      <td>[('무면허', 'Noun'), ('음주', 'Noun'), ('뺑소니', 'Nou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4564</th>\n      <td>엄마한테 잘해야 해요</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>장윤정 도 경완 폭풍성장 아들과 캠핑 근황언젠간 엄마도 함께 SHOT</td>\n      <td>[('엄마', 'Noun'), ('한테', 'Josa'), ('잘해야', 'Noun...</td>\n      <td>[('장윤정', 'Noun'), ('도', 'Noun'), ('경완', 'Noun'...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6004</th>\n      <td>이젠 뭐라 해도 진심이 1도 읍 다 달게 받기는 확인 안 하면 질책도 안 보고 못 ...</td>\n      <td>none</td>\n      <td>False</td>\n      <td>offensive</td>\n      <td>이종현 BJ 박민정 DM 논란 죄송 씨엔블루 탈퇴 결정 전문</td>\n      <td>[('이', 'Determiner'), ('젠', 'Noun'), ('뭐라', 'V...</td>\n      <td>[('이종현', 'Noun'), ('BJ', 'Alpha'), ('박민정', 'No...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7034</th>\n      <td>집사부 일체에 사부로 애들 잠깐 양념으로 나오는 건 그렇다 쳐도 이 영애 양심이 있...</td>\n      <td>none</td>\n      <td>False</td>\n      <td>offensive</td>\n      <td>집사부 일체 이영애 이상윤에 자녀 교육 상담 수학 어려워</td>\n      <td>[('집사부', 'Noun'), ('일체', 'Noun'), ('에', 'Josa'...</td>\n      <td>[('집사부', 'Noun'), ('일체', 'Noun'), ('이영애', 'Nou...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>549</th>\n      <td>계집들 댓글 보소 누가 아깝니 그런 개소리는 여자들 왜 하는 겨 여자 종특인가</td>\n      <td>gender</td>\n      <td>True</td>\n      <td>hate</td>\n      <td>단독 장현승 신수지 4개월째 열애 볼링이 공통분모</td>\n      <td>[('계집', 'Noun'), ('들', 'Suffix'), ('댓글', 'Noun...</td>\n      <td>[('단독', 'Noun'), ('장현승', 'Noun'), ('신수지', 'Nou...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6001</th>\n      <td>이제는 이렇게 퍼 오는 거 신고해서 걸러내야 한다,그냥 기자들에게 저들의 일상은 돈...</td>\n      <td>none</td>\n      <td>False</td>\n      <td>offensive</td>\n      <td>차세찌 한 채 아 달콤한 키즈카페 데이트 커플 운동화 SHOT</td>\n      <td>[('이제', 'Noun'), ('는', 'Josa'), ('이렇게', 'Adver...</td>\n      <td>[('차세', 'Verb'), ('찌', 'Noun'), ('한', 'Verb'),...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5973</th>\n      <td>이제 군대 피해의식에서 좀 벗어들 나 시지요</td>\n      <td>others</td>\n      <td>False</td>\n      <td>offensive</td>\n      <td>단독 유승준 새 앨범 사죄와 반성 담아 용 서해주시길</td>\n      <td>[('이제', 'Noun'), ('군대', 'Noun'), ('피해', 'Noun'...</td>\n      <td>[('단독', 'Noun'), ('유승준', 'Noun'), ('새', 'Noun'...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>7896 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=13)\n",
    "km_cluster.fit(tfidf_matrix_train)\n",
    "cluster_label = km_cluster.labels_\n",
    "train['cluster_label'] = cluster_label\n",
    "train.sort_values(by='cluster_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    4668\n",
       "1    1962\n",
       "2    1266\n",
       "Name: cluster_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "train['cluster_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_train = km_cluster.transform(tfidf_matrix_train)\n",
    "km_dev = km_cluster.transform(tfidf_matrix_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=13)\n",
    "km_cluster.fit(tfidf_matrix_dev)\n",
    "cluster_label = km_cluster.labels_\n",
    "dev['cluster_label'] = cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "params = {'C': [0.01, 0.1, 1, 5, 10]}\n",
    "gcv_lr = GridSearchCV(lr, param_grid=params, cv=5, scoring='accuracy', verbose=1)\n",
    "gcv_lr.fit(km_train, train['cluster_label'])\n",
    "gcv_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6518046709129511, 0.5328976494010175)"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "best_estimator = gcv_lr.best_estimator_\n",
    "preds = best_estimator.predict(km_dev)\n",
    "accuracy_score(dev['cluster_label'], preds), f1_score(preds, dev['cluster_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(tfidf_matrix_train, train['hate_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 9974 while Y.shape[1] == 31704",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-33de1870ddd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_matrix_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster_label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 **kwds))\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ball_tree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kd_tree'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1622\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1623\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[1;32m-> 1624\u001b[1;33m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[0;32m   1625\u001b[0m         if ((X is Y or Y is None)\n\u001b[0;32m   1626\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    270\u001b[0m            [1.41421356]])\n\u001b[0;32m    271\u001b[0m     \"\"\"\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;31m# If norms are passed as float32, they are unused. If arrays are passed as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    160\u001b[0m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[0;32m    161\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[1;32m--> 162\u001b[1;33m                              X.shape[1], Y.shape[1]))\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 9974 while Y.shape[1] == 31704"
     ]
    }
   ],
   "source": [
    "preds = knn.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['cluster_label'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datas/train_ver1', index_col=[0])\n",
    "dev = pd.read_csv('./datas/dev.hate.csv')\n",
    "dev.rename(columns={'label': 'hate_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "train_count = count_vec.fit_transform(train['comments'])\n",
    "tfidf_trans = TfidfTransformer()\n",
    "train_tfidf = tfidf_trans.fit_transform(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_count = count_vec.transform(dev['comments'])\n",
    "dev_tfidf = tfidf_trans.transform(dev_count)"
   ]
  },
  {
   "source": [
    "## countvect -> tfidf transformer -> knn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "clf = knn.fit(train_tfidf, train['hate_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.37154989384288745, 0.26709237989354595)"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "preds = clf.predict(dev_tfidf)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "37.15498938428875"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', knn),\n",
    "])\n",
    "\n",
    "text_clf.fit(train['comments'], train['hate_label'])\n",
    "test = dev['comments']\n",
    "pred = text_clf.predict(test)\n",
    "np.mean(pred == dev['hate_label'])*100"
   ]
  },
  {
   "source": [
    "## countvect -> tfidf transformer -> lr"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit time: 1.3053138256072998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_tfidf, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.46496815286624205, 0.4121162570736947)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "\n",
    "preds = lr.predict(dev_tfidf)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  }
 ]
}