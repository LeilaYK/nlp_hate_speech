{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "### Naive Bayes trial with first version of train data\n",
    "(remove punctuation marks,\n",
    "correct spacing between words,\n",
    "split sentences,\n",
    "classify part of speech)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               comments bias_label  \\\n",
       "7891                                         힘내세요,응원합니다       none   \n",
       "7892                                힘내세요,삼가 고인의 명복을 빕니다       none   \n",
       "7893                                      힘내세용 항상 응원합니닷       none   \n",
       "7894  힘내 소연기로 답해요,나도 53살 인데 이런 일 저런 일 다 있더라구 요인격을 믿습...       none   \n",
       "7895                                힘들면 관뒀어야지 그게 현명한 거다       none   \n",
       "\n",
       "      gender_label hate_label                                     news_title  \\\n",
       "7891         False       none                허지웅 허투루 넘길 말 없었다,솔직하게 드러냈던 속 사정   \n",
       "7892         False       none            이혜경 오 캐롤 공연 중 남편 오정욱 부 고 오열 속 발인 종합   \n",
       "7893         False       none                     설경구 송윤아 아들과 즐거운 하루 전 엄마니까요   \n",
       "7894         False       none  SC 현장 연예인 인생 협박 유감 미소 잃은 최민수 보복운전 혐의 2차 공판 종합   \n",
       "7895         False       none                단독 스태프 사망 사고 서른 이지만 결국 오늘 촬영 취소   \n",
       "\n",
       "                                            comment_pos  \\\n",
       "7891  [('힘내세요', 'Verb'), (',', 'Punctuation'), ('응원'...   \n",
       "7892  [('힘내세요', 'Verb'), (',', 'Punctuation'), ('삼가'...   \n",
       "7893  [('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...   \n",
       "7894  [('힘내', 'Verb'), ('소', 'Modifier'), ('연기', 'No...   \n",
       "7895  [('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...   \n",
       "\n",
       "                                              title_pos  \n",
       "7891  [('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...  \n",
       "7892  [('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...  \n",
       "7893  [('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...  \n",
       "7894  [('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...  \n",
       "7895  [('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>bias_label</th>\n      <th>gender_label</th>\n      <th>hate_label</th>\n      <th>news_title</th>\n      <th>comment_pos</th>\n      <th>title_pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7891</th>\n      <td>힘내세요,응원합니다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>허지웅 허투루 넘길 말 없었다,솔직하게 드러냈던 속 사정</td>\n      <td>[('힘내세요', 'Verb'), (',', 'Punctuation'), ('응원'...</td>\n      <td>[('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...</td>\n    </tr>\n    <tr>\n      <th>7892</th>\n      <td>힘내세요,삼가 고인의 명복을 빕니다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>이혜경 오 캐롤 공연 중 남편 오정욱 부 고 오열 속 발인 종합</td>\n      <td>[('힘내세요', 'Verb'), (',', 'Punctuation'), ('삼가'...</td>\n      <td>[('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...</td>\n    </tr>\n    <tr>\n      <th>7893</th>\n      <td>힘내세용 항상 응원합니닷</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>설경구 송윤아 아들과 즐거운 하루 전 엄마니까요</td>\n      <td>[('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...</td>\n      <td>[('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...</td>\n    </tr>\n    <tr>\n      <th>7894</th>\n      <td>힘내 소연기로 답해요,나도 53살 인데 이런 일 저런 일 다 있더라구 요인격을 믿습...</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>SC 현장 연예인 인생 협박 유감 미소 잃은 최민수 보복운전 혐의 2차 공판 종합</td>\n      <td>[('힘내', 'Verb'), ('소', 'Modifier'), ('연기', 'No...</td>\n      <td>[('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...</td>\n    </tr>\n    <tr>\n      <th>7895</th>\n      <td>힘들면 관뒀어야지 그게 현명한 거다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>단독 스태프 사망 사고 서른 이지만 결국 오늘 촬영 취소</td>\n      <td>[('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...</td>\n      <td>[('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "train = pd.read_csv('./datas/train_ver1', index_col=[0])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 7896 entries, 0 to 7895\nData columns (total 7 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   comments      7896 non-null   object\n 1   bias_label    7896 non-null   object\n 2   gender_label  7896 non-null   bool  \n 3   hate_label    7896 non-null   object\n 4   news_title    7896 non-null   object\n 5   comment_pos   7896 non-null   object\n 6   title_pos     7896 non-null   object\ndtypes: bool(1), object(6)\nmemory usage: 439.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train['comments'].to_list()\n",
    "b = train['hate_label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list = list(zip(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "t = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = [(t.morphs(sentence[0]), sentence[1]) for sentence in train_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv('https://bab2min.tistory.com/attachment/cfile2.uf@241D6F475873C2B1010DEA.txt', sep='\\t', header=None, names=['형태','품사','비율'])\n",
    "stopwords_list = stopwords['형태'].tolist()\n",
    "\n",
    "def process_text(text):\n",
    "    clean_words = [word for word in text if word not in stopwords_list]\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = process_text(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = set([i for d in train_docs for i in d[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_exists(doc):\n",
    "    return {word: (word in set(doc)) for word in all_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xy = [(term_exists(d), c) for d,c in train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n",
      "                      돼지 = True             hate : none   =     44.4 : 1.0\n",
      "                       쳐 = True             hate : none   =     40.5 : 1.0\n",
      "                      생긴 = True             hate : none   =     37.1 : 1.0\n",
      "                      재앙 = True             hate : offens =     36.2 : 1.0\n",
      "                      새끼 = True             hate : none   =     31.0 : 1.0\n",
      "                     OOO = True             hate : none   =     24.9 : 1.0\n",
      "                       ㅈ = True             hate : none   =     18.8 : 1.0\n",
      "                      쟁이 = True             hate : offens =     18.7 : 1.0\n",
      "                      페미 = True             hate : offens =     18.7 : 1.0\n",
      "                      지랄 = True             hate : none   =     17.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_xy)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              comments hate_label\n",
       "466                                  지현우 범죄 저지르지 않았나요?  offensive\n",
       "467                                    여자인생 망칠 일 있나 ㅋㅋ       hate\n",
       "468            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?  offensive\n",
       "469  할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...       hate\n",
       "470  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...       none"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>hate_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>466</th>\n      <td>지현우 범죄 저지르지 않았나요?</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>여자인생 망칠 일 있나 ㅋㅋ</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>470</th>\n      <td>남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...</td>\n      <td>none</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "dev = pd.read_csv('./datas/dev.hate.csv')\n",
    "dev.rename(columns={'label': 'hate_label'}, inplace=True)\n",
    "dev.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'none'"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "test_sentence = '여자인생 망칠 일 있나 ㅋㅋ'\n",
    "classifier.classify(term_exists(t.morphs(test_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for sentence in dev['comments']:\n",
    "    pred.append(classifier.classify(term_exists(t.morphs(sentence))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.509707870249717"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "f1_score(pred, dev['hate_label'], average='macro')"
   ]
  },
  {
   "source": [
    "### Naive Bayes trial with second version of train data\n",
    "(remove punctuation marks,\n",
    "classify part of speech)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           comments bias_label  gender_label  \\\n",
       "7891                                     힘내세요 응원합니다       none         False   \n",
       "7892                             힘내세요삼가 고인의 명복을 빕니다       none         False   \n",
       "7893                                 힘내세용 항상 응원합니닷        none         False   \n",
       "7894  힘내소연기로 답해요나도 53살 인데 이런일 저런일 다 있더라구요인격을 믿습니다홨팅       none         False   \n",
       "7895                             힘들면 관뒀어야지 그게 현명한거다       none         False   \n",
       "\n",
       "     hate_label                                 news_title  \\\n",
       "7891       none             허지웅 허투루 넘길 말 없었다 솔직하게 드러냈던 속사정   \n",
       "7892       none         이혜경 오 캐롤 공연 중 남편 오정욱 부고 오열 속 발인 종합   \n",
       "7893       none                 설경구 송윤아 아들과 즐거운 하루 전 엄마니까요   \n",
       "7894       none  SC현장연예인 인생 협박 유감 미소잃은 최민수 보복운전 혐의 2차 공판종합   \n",
       "7895       none               단독스태프 사망사고 서른이지만 결국 오늘 촬영 취소   \n",
       "\n",
       "                                            comment_pos  \\\n",
       "7891  [('힘내세요', 'Verb'), ('응원', 'Noun'), ('합니다', 'Ve...   \n",
       "7892  [('힘내세요', 'Verb'), ('삼가', 'Verb'), ('고인', 'Nou...   \n",
       "7893  [('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...   \n",
       "7894  [('힘내소', 'Verb'), ('연기', 'Noun'), ('로', 'Josa'...   \n",
       "7895  [('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...   \n",
       "\n",
       "                                              title_pos  \n",
       "7891  [('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...  \n",
       "7892  [('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...  \n",
       "7893  [('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...  \n",
       "7894  [('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...  \n",
       "7895  [('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>bias_label</th>\n      <th>gender_label</th>\n      <th>hate_label</th>\n      <th>news_title</th>\n      <th>comment_pos</th>\n      <th>title_pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7891</th>\n      <td>힘내세요 응원합니다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>허지웅 허투루 넘길 말 없었다 솔직하게 드러냈던 속사정</td>\n      <td>[('힘내세요', 'Verb'), ('응원', 'Noun'), ('합니다', 'Ve...</td>\n      <td>[('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...</td>\n    </tr>\n    <tr>\n      <th>7892</th>\n      <td>힘내세요삼가 고인의 명복을 빕니다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>이혜경 오 캐롤 공연 중 남편 오정욱 부고 오열 속 발인 종합</td>\n      <td>[('힘내세요', 'Verb'), ('삼가', 'Verb'), ('고인', 'Nou...</td>\n      <td>[('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...</td>\n    </tr>\n    <tr>\n      <th>7893</th>\n      <td>힘내세용 항상 응원합니닷</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>설경구 송윤아 아들과 즐거운 하루 전 엄마니까요</td>\n      <td>[('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...</td>\n      <td>[('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...</td>\n    </tr>\n    <tr>\n      <th>7894</th>\n      <td>힘내소연기로 답해요나도 53살 인데 이런일 저런일 다 있더라구요인격을 믿습니다홨팅</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>SC현장연예인 인생 협박 유감 미소잃은 최민수 보복운전 혐의 2차 공판종합</td>\n      <td>[('힘내소', 'Verb'), ('연기', 'Noun'), ('로', 'Josa'...</td>\n      <td>[('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...</td>\n    </tr>\n    <tr>\n      <th>7895</th>\n      <td>힘들면 관뒀어야지 그게 현명한거다</td>\n      <td>none</td>\n      <td>False</td>\n      <td>none</td>\n      <td>단독스태프 사망사고 서른이지만 결국 오늘 촬영 취소</td>\n      <td>[('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...</td>\n      <td>[('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "train_2 = pd.read_csv('./datas/train_ver2', index_col=[0])\n",
    "train_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = train_2['comments'].to_list()\n",
    "d = train_2['hate_label'].to_list()\n",
    "train2_list = list(zip(c, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n",
      "                       년 = True             hate : none   =     37.8 : 1.0\n",
      "                      재앙 = True             hate : offens =     36.2 : 1.0\n",
      "                      돼지 = True             hate : none   =     31.0 : 1.0\n",
      "                      새끼 = True             hate : none   =     29.8 : 1.0\n",
      "                       쳐 = True             hate : none   =     26.3 : 1.0\n",
      "                     OOO = True             hate : none   =     24.9 : 1.0\n",
      "                      페미 = True             hate : offens =     24.8 : 1.0\n",
      "                     개돼지 = True             hate : offens =     24.0 : 1.0\n",
      "                      미투 = True             hate : none   =     20.1 : 1.0\n",
      "                       ㅈ = True             hate : none   =     18.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "train2_docs = [(t.morphs(sentence[0]), sentence[1]) for sentence in train2_list]\n",
    "train2_docs = process_text(train2_docs)\n",
    "all_words = set([i for d in train2_docs for i in d[0]])\n",
    "train2_xy = [(term_exists(d), c) for d,c in train2_docs]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train2_xy)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5254201266795134"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "pred2 = []\n",
    "for sentence in dev['comments']:\n",
    "    pred2.append(classifier.classify(term_exists(t.morphs(sentence))))\n",
    "\n",
    "f1_score(pred2, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}