{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt; t = Okt()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>bias_label</th>\n",
       "      <th>gender_label</th>\n",
       "      <th>hate_label</th>\n",
       "      <th>news_title</th>\n",
       "      <th>comment_pos</th>\n",
       "      <th>title_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>힘내세요,응원합니다</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>허지웅 허투루 넘길 말 없었다,솔직하게 드러냈던 속 사정</td>\n",
       "      <td>[('힘내세요', 'Verb'), (',', 'Punctuation'), ('응원'...</td>\n",
       "      <td>[('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>힘내세요,삼가 고인의 명복을 빕니다</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>이혜경 오 캐롤 공연 중 남편 오정욱 부 고 오열 속 발인 종합</td>\n",
       "      <td>[('힘내세요', 'Verb'), (',', 'Punctuation'), ('삼가'...</td>\n",
       "      <td>[('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>힘내세용 항상 응원합니닷</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>설경구 송윤아 아들과 즐거운 하루 전 엄마니까요</td>\n",
       "      <td>[('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...</td>\n",
       "      <td>[('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>힘내 소연기로 답해요,나도 53살 인데 이런 일 저런 일 다 있더라구 요인격을 믿습...</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>SC 현장 연예인 인생 협박 유감 미소 잃은 최민수 보복운전 혐의 2차 공판 종합</td>\n",
       "      <td>[('힘내', 'Verb'), ('소', 'Modifier'), ('연기', 'No...</td>\n",
       "      <td>[('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>힘들면 관뒀어야지 그게 현명한 거다</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>단독 스태프 사망 사고 서른 이지만 결국 오늘 촬영 취소</td>\n",
       "      <td>[('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...</td>\n",
       "      <td>[('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comments bias_label  \\\n",
       "7891                                         힘내세요,응원합니다       none   \n",
       "7892                                힘내세요,삼가 고인의 명복을 빕니다       none   \n",
       "7893                                      힘내세용 항상 응원합니닷       none   \n",
       "7894  힘내 소연기로 답해요,나도 53살 인데 이런 일 저런 일 다 있더라구 요인격을 믿습...       none   \n",
       "7895                                힘들면 관뒀어야지 그게 현명한 거다       none   \n",
       "\n",
       "      gender_label hate_label                                     news_title  \\\n",
       "7891         False       none                허지웅 허투루 넘길 말 없었다,솔직하게 드러냈던 속 사정   \n",
       "7892         False       none            이혜경 오 캐롤 공연 중 남편 오정욱 부 고 오열 속 발인 종합   \n",
       "7893         False       none                     설경구 송윤아 아들과 즐거운 하루 전 엄마니까요   \n",
       "7894         False       none  SC 현장 연예인 인생 협박 유감 미소 잃은 최민수 보복운전 혐의 2차 공판 종합   \n",
       "7895         False       none                단독 스태프 사망 사고 서른 이지만 결국 오늘 촬영 취소   \n",
       "\n",
       "                                            comment_pos  \\\n",
       "7891  [('힘내세요', 'Verb'), (',', 'Punctuation'), ('응원'...   \n",
       "7892  [('힘내세요', 'Verb'), (',', 'Punctuation'), ('삼가'...   \n",
       "7893  [('힘내세용', 'Verb'), ('항상', 'Noun'), ('응원', 'Nou...   \n",
       "7894  [('힘내', 'Verb'), ('소', 'Modifier'), ('연기', 'No...   \n",
       "7895  [('힘들면', 'Adjective'), ('관', 'Noun'), ('뒀어야지',...   \n",
       "\n",
       "                                              title_pos  \n",
       "7891  [('허지웅', 'Noun'), ('허투루', 'Noun'), ('넘길', 'Ver...  \n",
       "7892  [('이혜경', 'Noun'), ('오', 'Noun'), ('캐롤', 'Noun'...  \n",
       "7893  [('설경구', 'Noun'), ('송윤아', 'Noun'), ('아들', 'Nou...  \n",
       "7894  [('SC', 'Alpha'), ('현장', 'Noun'), ('연예인', 'Nou...  \n",
       "7895  [('단독', 'Noun'), ('스태프', 'Noun'), ('사망', 'Noun...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./datas/train_ver1', index_col=[0])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>hate_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>지현우 범죄 저지르지 않았나요?</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>여자인생 망칠 일 있나 ㅋㅋ</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments hate_label\n",
       "466                                  지현우 범죄 저지르지 않았나요?  offensive\n",
       "467                                    여자인생 망칠 일 있나 ㅋㅋ       hate\n",
       "468            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?  offensive\n",
       "469  할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...       hate\n",
       "470  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...       none"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv('./datas/dev.hate.csv')\n",
    "dev.rename(columns={'label': 'hate_label'}, inplace=True)\n",
    "dev.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_tokenizer(text):\n",
    "    tokens_ko = t.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luvu1\\anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(tokenizer=t_tokenizer, ngram_range=(1,2), min_df=5, max_df=0.9, sublinear_tf=True, max_features=50000)\n",
    "tfidf_vect.fit(train['comments'])\n",
    "tfidf_matrix_train = tfidf_vect.transform(train['comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMClassifier compare train and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 9.332458257675171\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "lgbm_clf = LGBMClassifier(n_estimators=400)\n",
    "lgbm_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5414012738853503, 0.5370598485758923)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "\n",
    "tfidf_matrix_dev = tfidf_vect.transform(dev['comments'])\n",
    "preds = lgbm_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier compare train and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 10.518273115158081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_clf = DecisionTreeClassifier(max_depth=2, random_state=13)\n",
    "decision_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4118895966029724, 0.33302547396349347)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = decision_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression compare train and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 10.634006261825562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='sag', penalty='l2', random_state= 1000)\n",
    "lr.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5944798301486199, 0.5866447728516694)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lr.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_result = []\n",
    "\n",
    "for n in range(0, len(dev['hate_label'])):\n",
    "    if preds[n] != dev['hate_label'][n]:\n",
    "        wrong_result.append(n)\n",
    "len(wrong_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 199,\n",
       " 171,\n",
       " 219,\n",
       " 70,\n",
       " 324,\n",
       " 273,\n",
       " 70,\n",
       " 55,\n",
       " 414,\n",
       " 393,\n",
       " 425,\n",
       " 301,\n",
       " 225,\n",
       " 50,\n",
       " 433,\n",
       " 92,\n",
       " 325,\n",
       " 199,\n",
       " 270,\n",
       " 224,\n",
       " 325,\n",
       " 173,\n",
       " 358,\n",
       " 96,\n",
       " 186,\n",
       " 352,\n",
       " 44,\n",
       " 154,\n",
       " 312,\n",
       " 345,\n",
       " 100,\n",
       " 332,\n",
       " 329,\n",
       " 230,\n",
       " 95,\n",
       " 438,\n",
       " 173,\n",
       " 219,\n",
       " 159,\n",
       " 111,\n",
       " 66,\n",
       " 426,\n",
       " 329,\n",
       " 96,\n",
       " 387,\n",
       " 272,\n",
       " 114,\n",
       " 394,\n",
       " 92,\n",
       " 431,\n",
       " 61,\n",
       " 157,\n",
       " 281,\n",
       " 359,\n",
       " 309,\n",
       " 217,\n",
       " 163,\n",
       " 41,\n",
       " 230,\n",
       " 15,\n",
       " 2,\n",
       " 193,\n",
       " 252,\n",
       " 113,\n",
       " 37,\n",
       " 173,\n",
       " 147,\n",
       " 147,\n",
       " 220,\n",
       " 76,\n",
       " 272,\n",
       " 41,\n",
       " 71,\n",
       " 442,\n",
       " 241,\n",
       " 347,\n",
       " 466,\n",
       " 52,\n",
       " 210,\n",
       " 262,\n",
       " 100,\n",
       " 43,\n",
       " 50,\n",
       " 252,\n",
       " 151,\n",
       " 225,\n",
       " 100,\n",
       " 193,\n",
       " 49,\n",
       " 325,\n",
       " 434,\n",
       " 271,\n",
       " 95,\n",
       " 431,\n",
       " 258,\n",
       " 309,\n",
       " 239,\n",
       " 469,\n",
       " 225,\n",
       " 226,\n",
       " 322,\n",
       " 11,\n",
       " 352,\n",
       " 341,\n",
       " 309,\n",
       " 391,\n",
       " 469,\n",
       " 259,\n",
       " 11,\n",
       " 163,\n",
       " 181,\n",
       " 217,\n",
       " 50,\n",
       " 401,\n",
       " 173,\n",
       " 76,\n",
       " 198,\n",
       " 453,\n",
       " 312,\n",
       " 322,\n",
       " 345,\n",
       " 387,\n",
       " 171,\n",
       " 308,\n",
       " 403,\n",
       " 216,\n",
       " 181,\n",
       " 172,\n",
       " 298,\n",
       " 380,\n",
       " 431,\n",
       " 224,\n",
       " 217,\n",
       " 409,\n",
       " 281,\n",
       " 24,\n",
       " 138,\n",
       " 43,\n",
       " 166,\n",
       " 19,\n",
       " 332,\n",
       " 394,\n",
       " 74,\n",
       " 322,\n",
       " 458,\n",
       " 470,\n",
       " 171,\n",
       " 312,\n",
       " 235,\n",
       " 453,\n",
       " 387,\n",
       " 403,\n",
       " 322,\n",
       " 220,\n",
       " 199,\n",
       " 331,\n",
       " 149,\n",
       " 179,\n",
       " 273,\n",
       " 47,\n",
       " 224,\n",
       " 469,\n",
       " 401,\n",
       " 225,\n",
       " 156,\n",
       " 285,\n",
       " 66,\n",
       " 147,\n",
       " 52,\n",
       " 272,\n",
       " 29,\n",
       " 89,\n",
       " 442,\n",
       " 297,\n",
       " 302,\n",
       " 11,\n",
       " 157,\n",
       " 387,\n",
       " 11,\n",
       " 252,\n",
       " 422,\n",
       " 154,\n",
       " 298,\n",
       " 351,\n",
       " 347,\n",
       " 433,\n",
       " 401,\n",
       " 425,\n",
       " 259,\n",
       " 119,\n",
       " 11,\n",
       " 470,\n",
       " 127,\n",
       " 440,\n",
       " 111,\n",
       " 2,\n",
       " 345,\n",
       " 157,\n",
       " 115,\n",
       " 122,\n",
       " 279,\n",
       " 435,\n",
       " 171,\n",
       " 66,\n",
       " 337,\n",
       " 10,\n",
       " 433,\n",
       " 466,\n",
       " 138,\n",
       " 353,\n",
       " 30,\n",
       " 225,\n",
       " 248,\n",
       " 403,\n",
       " 34,\n",
       " 345,\n",
       " 220,\n",
       " 16,\n",
       " 393,\n",
       " 387,\n",
       " 359,\n",
       " 440,\n",
       " 151,\n",
       " 330,\n",
       " 83,\n",
       " 353,\n",
       " 238,\n",
       " 302,\n",
       " 11,\n",
       " 293,\n",
       " 49,\n",
       " 263,\n",
       " 401,\n",
       " 78,\n",
       " 133,\n",
       " 115,\n",
       " 415,\n",
       " 403,\n",
       " 351,\n",
       " 298,\n",
       " 323,\n",
       " 470,\n",
       " 367,\n",
       " 220,\n",
       " 164,\n",
       " 302,\n",
       " 30,\n",
       " 246,\n",
       " 259,\n",
       " 101,\n",
       " 301,\n",
       " 379,\n",
       " 347,\n",
       " 23,\n",
       " 291,\n",
       " 446,\n",
       " 61,\n",
       " 401,\n",
       " 226,\n",
       " 367,\n",
       " 41,\n",
       " 30,\n",
       " 229,\n",
       " 220,\n",
       " 181,\n",
       " 291,\n",
       " 358,\n",
       " 96,\n",
       " 358,\n",
       " 209,\n",
       " 301,\n",
       " 414,\n",
       " 347,\n",
       " 346,\n",
       " 255,\n",
       " 259,\n",
       " 24,\n",
       " 220,\n",
       " 273,\n",
       " 435,\n",
       " 276,\n",
       " 229,\n",
       " 37,\n",
       " 173,\n",
       " 331,\n",
       " 403,\n",
       " 232,\n",
       " 293,\n",
       " 151,\n",
       " 381,\n",
       " 268,\n",
       " 433,\n",
       " 78,\n",
       " 88,\n",
       " 159,\n",
       " 374,\n",
       " 28,\n",
       " 24,\n",
       " 391]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "samples = random.choices(population=wrong_result, k=300)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    offensive\n",
       "1         none\n",
       "2    offensive\n",
       "3    offensive\n",
       "4         none\n",
       "..         ...\n",
       "188       none\n",
       "189       none\n",
       "190       none\n",
       "191       none\n",
       "192       hate\n",
       "\n",
       "[193 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(preds[wrong_result])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luvu1\\anaconda3\\envs\\nltk\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>hate_label</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라</td>\n",
       "      <td>hate</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>설마 ㅈ 현정 작가 아니지</td>\n",
       "      <td>hate</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>이경규가 이런거보면 세련되긴함 저 나이에 차은우 누가 알꼬 아무리 잘생겼다해도 배워...</td>\n",
       "      <td>none</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>아c발 어쩌라고 뭔기사가계속나오냐</td>\n",
       "      <td>hate</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>둘이 화장실가서 싸우길</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>강용석도 찌질하네 과거들추기는 추하다</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>지현우 범죄 저지르지 않았나요</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>할매젖x 뱃살x 몸매 s라인 유륜은 적당해야됨너무크거나 너무 작아도 x 엉덩이가 빵...</td>\n",
       "      <td>hate</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>남자가 잘못한거라면 반성도 없다면나였다면 여자처럼 아주 못되게 할것같다,왜 나를 배...</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments hate_label      error\n",
       "2           알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라       hate  offensive\n",
       "3                                       설마 ㅈ 현정 작가 아니지       hate       none\n",
       "10   이경규가 이런거보면 세련되긴함 저 나이에 차은우 누가 알꼬 아무리 잘생겼다해도 배워...       none  offensive\n",
       "11                                  아c발 어쩌라고 뭔기사가계속나오냐       hate  offensive\n",
       "15                                        둘이 화장실가서 싸우길  offensive       none\n",
       "..                                                 ...        ...        ...\n",
       "463                               강용석도 찌질하네 과거들추기는 추하다  offensive       none\n",
       "466                                   지현우 범죄 저지르지 않았나요  offensive       none\n",
       "468             근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는  offensive       none\n",
       "469  할매젖x 뱃살x 몸매 s라인 유륜은 적당해야됨너무크거나 너무 작아도 x 엉덩이가 빵...       hate       none\n",
       "470  남자가 잘못한거라면 반성도 없다면나였다면 여자처럼 아주 못되게 할것같다,왜 나를 배...       none       hate\n",
       "\n",
       "[193 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = dev.iloc[wrong_result]\n",
    "df1['error'] = preds[wrong_result]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./datas/df1_wrong_result', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offensive</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hate_label\n",
       "offensive         117\n",
       "hate               62\n",
       "none               14"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['hate_label'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offensive</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           error\n",
       "none         131\n",
       "offensive     46\n",
       "hate          16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['error'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['hate', 'none', 'offensive'], dtype=object),\n",
       " array([ 76, 277, 118], dtype=int64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier compare train and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 1442.2418930530548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=13)\n",
    "gb_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5010615711252654, 0.46740606218993697)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gb_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier compare train and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luvu1\\anaconda3\\envs\\nltk\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 1450.349557876587\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "xgb_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "print('fit time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5307855626326964, 0.5075256284933704)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = xgb_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomForestClassifier compare train and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33970276008492567, 0.16904384574749076)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "r_clf = RandomForestClassifier(max_depth=4, random_state=13)\n",
    "r_clf.fit(tfidf_matrix_train, train['hate_label'])\n",
    "\n",
    "preds = r_clf.predict(tfidf_matrix_dev)\n",
    "accuracy_score(dev['hate_label'], preds), f1_score(preds, dev['hate_label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, class_train, class_test = train_test_split(tfidf_matrix_train, train['hate_label'], test_size=0.2, stratify=train['hate_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = []\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "models.append(('LogisticRegression', LogisticRegression()))\n",
    "models.append(('LGBMClassifier', LGBMClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc :  0.9990500316656111\n",
      "Test Acc :  0.5379746835443038\n",
      "Train Acc :  0.9990500316656111\n",
      "Test Acc :  0.47025316455696203\n",
      "Train Acc :  0.5508233058898037\n",
      "Test Acc :  0.5082278481012659\n",
      "Train Acc :  0.6489867004433185\n",
      "Test Acc :  0.5208860759493671\n",
      "Train Acc :  0.8552881570614312\n",
      "Test Acc :  0.5620253164556962\n",
      "Train Acc :  0.8180810639645345\n",
      "Test Acc :  0.5430379746835443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(msg_train, class_train)\n",
    "    \n",
    "    y_pred_tr = clf.predict(msg_train)\n",
    "    y_pred_test = clf.predict(msg_test)\n",
    "    \n",
    "    print('Train Acc : ', accuracy_score(class_train, y_pred_tr))\n",
    "    print('Test Acc : ', accuracy_score(class_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "names = []\n",
    "f1score = []\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(msg_train, class_train)\n",
    "    \n",
    "    y_pred_tr = clf.predict(msg_train)\n",
    "    y_pred_test = clf.predict(msg_test)\n",
    "    \n",
    "    names.append(name)\n",
    "    test_score.append(accuracy_score(class_test, y_pred_test))\n",
    "    train_score.append(accuracy_score(class_train, y_pred_tr))\n",
    "    f1score.append(f1_score(class_test, y_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.999050</td>\n",
       "      <td>0.538608</td>\n",
       "      <td>0.493020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.999050</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.452573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.550823</td>\n",
       "      <td>0.508228</td>\n",
       "      <td>0.463536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.648670</td>\n",
       "      <td>0.527848</td>\n",
       "      <td>0.466697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.855288</td>\n",
       "      <td>0.562025</td>\n",
       "      <td>0.532790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.818081</td>\n",
       "      <td>0.543038</td>\n",
       "      <td>0.516057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model name  train score  test score  f1 score\n",
       "0      RandomForestClassifier     0.999050    0.538608  0.493020\n",
       "1      DecisionTreeClassifier     0.999050    0.478481  0.452573\n",
       "2          AdaBoostClassifier     0.550823    0.508228  0.463536\n",
       "3  GradientBoostingClassifier     0.648670    0.527848  0.466697\n",
       "4          LogisticRegression     0.855288    0.562025  0.532790\n",
       "5              LGBMClassifier     0.818081    0.543038  0.516057"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'model name':names, \n",
    "                       'train score':train_score, \n",
    "                       'test score':test_score,\n",
    "                       'f1 score': f1score}) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
